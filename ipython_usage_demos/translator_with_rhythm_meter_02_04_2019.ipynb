{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from time import monotonic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isdir('/srv/hd6/data'): # shad-gpu\n",
    "    data_root_dir = '/srv/hd6/data/Poem2Poem/data'\n",
    "elif os.path.isdir('/data'): # shad-almaren\n",
    "    data_root_dir = 'data'\n",
    "else:\n",
    "    assert False\n",
    "assert os.path.isdir(data_root_dir)\n",
    "\n",
    "common_path_prefix = data_root_dir + '/ParallelEnRu/Amalgama/amalgama-adj-en-ru-lines-rev-norm'\n",
    "train_path_prefix = common_path_prefix + '-train'\n",
    "dev_path_prefix   = common_path_prefix + '-dev'\n",
    "\n",
    "train_bpe_en_path          = train_path_prefix + '-bpe-40k-en.txt'\n",
    "train_bpe_ru_path          = train_path_prefix + '-bpe-40k-ru.txt'\n",
    "train_vocab_en_path        = train_path_prefix + '-bpe-40k-vocab-en.txt'\n",
    "train_vocab_ru_path        = train_path_prefix + '-bpe-40k-vocab-ru.txt'\n",
    "train_dataset_tok_ids_path = train_path_prefix + '-bpe-40k-tok-ids.txt'\n",
    "\n",
    "dev_dataset_tok_ids_path = dev_path_prefix + '-bpe-40k-tok-ids.txt'\n",
    "dev_dataset_toks_path    = dev_path_prefix + '-bpe-40k-toks.txt'\n",
    "    \n",
    "SHAKESPEARE_SONNETS_PARALLEL_PATH = data_root_dir + \\\n",
    "                                    '/Sonnets/ShakespeareSonnets/shakespeare-sonnets-en-ru-marshak.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading English tokenizer...\n",
      " Loading BPE...\n",
      " Reading vocabulary file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38362it [00:00, 1289960.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " token count: 38k\n",
      "Loading Russian tokenizer...\n",
      " Loading BPE...\n",
      " Reading vocabulary file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "39817it [00:00, 1158675.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " token count: 40k\n",
      "Reading train token ID lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1602202it [00:20, 77746.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " updating token IDs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1602202/1602202 [00:07<00:00, 213299.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dev token ID lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "287117it [00:03, 83780.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " updating token IDs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 287117/287117 [00:01<00:00, 195110.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dev token lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "287117it [00:02, 102429.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "\n",
    "\n",
    "\n",
    "def _count_to_str(n):\n",
    "    if n >= 1_000_000:\n",
    "        n /= 1_000_000\n",
    "        suffix = 'M'\n",
    "    elif n >= 1_000:\n",
    "        n /= 1_000\n",
    "        suffix = 'k'\n",
    "    else:\n",
    "        return str(n)\n",
    "    \n",
    "    return ('{:.1f}' if n < 10 else '{:.0f}').format(n) + suffix\n",
    "\n",
    "def _get_reversed(line):\n",
    "    return ''.join(reversed(line))\n",
    "\n",
    "\n",
    "\n",
    "def _open_read_text(path):\n",
    "    return open(path, mode = 'r', encoding = 'utf-8', newline = '\\n') # input lines are only terminated by '\\n'\n",
    "\n",
    "def _open_write_text(path):\n",
    "    return open(path, mode = 'w', encoding = 'utf-8', newline = '') # no newline translation\n",
    "\n",
    "\n",
    "def _load_bpe(bpe_path, separator):\n",
    "    with _open_read_text(bpe_path) as f: # input lines are only terminated by '\\n'\n",
    "        return BPE(codes = f, separator = separator)\n",
    "\n",
    "def _update_tok_id_pairs(tok_pairs):\n",
    "    \n",
    "    # Update 'tok_pairs' where 'UNK' had ID = 0:\n",
    "    for tok_pair in tqdm(tok_pairs):\n",
    "        for toks in tok_pair:\n",
    "            assert type(toks) == np.ndarray\n",
    "            toks += 2\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, regular_tokens, reversed_, chars):\n",
    "        \n",
    "        if chars:\n",
    "            bos, eos, unk = '^', '$', '?'\n",
    "        else:\n",
    "            bos, eos, unk = '<BOS>', '<EOS>', '<UNK>'\n",
    "        \n",
    "            if reversed_:\n",
    "                bos, eos, unk = map(_get_reversed, (bos, eos, unk))\n",
    "        \n",
    "        assert all([t not in (bos, eos, unk) and len(t) > 0 for t in regular_tokens])\n",
    "\n",
    "        tokens = [bos, eos, unk] + regular_tokens\n",
    "        \n",
    "        self.tokens_separator = '' if chars else ' '\n",
    "        self.tokens = tokens\n",
    "        self.token_to_ix = {t:i for i, t in enumerate(tokens)}\n",
    "        self.bos_ix, self.eos_ix, self.unk_ix = 0, 1, 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "    \n",
    "    def tokens_to_ids(self, tokens):\n",
    "        return np.array([self.token_to_ix.get(tok, self.unk_ix)\n",
    "                         for tok in tokens])\n",
    "    \n",
    "    def token_ids_to_str(self, tok_ids: np.ndarray):\n",
    "        assert type(tok_ids) == np.ndarray, 'NDarray expected as \"tok_ids\"'\n",
    "        \n",
    "        return self.tokens_separator.join(self.tokens[i] for i in tok_ids)\n",
    "\n",
    "    \n",
    "    def tok_ids_seq_to_matrix(self, tok_ids_seq, max_matrix_width):\n",
    "        \"\"\"\n",
    "        Convert variable length token ID sequences into fixed size matrix\n",
    "        If 'max_matrix_width' is not 'None', matrix is truncated\n",
    "        \"\"\"\n",
    "        max_tok_count = max(map(len, tok_ids_seq))\n",
    "        matrix_width = max_tok_count + 2 # For BOS and EOS\n",
    "\n",
    "        if max_matrix_width is not None and matrix_width > max_matrix_width:\n",
    "            assert max_matrix_width >= 1 # For BOS, EOS can be truncated\n",
    "            matrix_width = max_matrix_width\n",
    "            max_tok_count = matrix_width - 1\n",
    "\n",
    "        matrix = np.full((len(tok_ids_seq), matrix_width),\n",
    "                         self.eos_ix,\n",
    "                         dtype = np.int32)\n",
    "        matrix[:, 0] = self.bos_ix\n",
    "\n",
    "        for i, tok_ids in enumerate(tok_ids_seq):\n",
    "            row = tok_ids[:max_tok_count]\n",
    "            matrix[i, 1 : 1 + len(row)] = row\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def matrix_to_tok_ids_seq(self, matrix):\n",
    "        \"\"\"\n",
    "        Convert matrix of token ids into variable length token ID sequences\n",
    "        :param matrix: matrix of tokens of int32, shape=[batch,time]\n",
    "        \"\"\"\n",
    "\n",
    "        assert np.all(matrix[:, 0] == self.bos_ix)\n",
    "\n",
    "        tok_ids_seq = []\n",
    "        for tok_ids in matrix[:, 1:]:\n",
    "            [eos_indices] = np.where(tok_ids == self.eos_ix)\n",
    "            if len(eos_indices) != 0:\n",
    "                tok_ids = tok_ids[:eos_indices[0]]\n",
    "            tok_ids_seq.append(tok_ids)\n",
    "        return tok_ids_seq\n",
    "\n",
    "\n",
    "def _load_tok_pairs(path, tok_ids):\n",
    "    \n",
    "    tok_pairs = []\n",
    "    \n",
    "    with _open_read_text(path) as f:\n",
    "\n",
    "        for line in tqdm(f):\n",
    "            assert line[-1] == '\\n'\n",
    "            tok_pair = line[:-1].split(';')\n",
    "            assert len(tok_pair) == 2\n",
    "            \n",
    "            tok_pair = [s.split() for s in tok_pair]\n",
    "            \n",
    "            if tok_ids:\n",
    "                tok_pair = [np.array([int(s, 16) for s in toks], dtype = np.int32)\n",
    "                            for toks in tok_pair]\n",
    "            \n",
    "            tok_pairs.append(tuple(tok_pair))\n",
    "    \n",
    "    return tok_pairs\n",
    "\n",
    "\n",
    "\n",
    "def _remove_punc_en(line, lower):\n",
    "    if lower:\n",
    "        line = line.lower()\n",
    "    line = re.sub(r\"[^\\w\\s'-]|_\", ' ', line) # leave '-' and \"'\", remove '_'\n",
    "    \n",
    "    # Leave only one '-' or \"'\" in row:\n",
    "    \n",
    "    line = re.sub(\"'['-]+\", \"' \", line)  # ams'- he said\n",
    "    line = re.sub(\"['-]+'\", \" '\", line)  # -'John' said\n",
    "    line = re.sub(\"['-]['-]+\", ' ', line) # -'- or --\n",
    "    \n",
    "    line = ' ' + line + ' '\n",
    "    line = re.sub(r'-\\s|\\s-', ' ', line)  # leve '-' only inside words\n",
    "    line = re.sub(r\"\\s'\\s\", ' ', line)    # remove \"'\" alone\n",
    "    \n",
    "    line = re.sub(r'\\s+', ' ', line)\n",
    "    return line.strip()\n",
    "\n",
    "def _remove_punc_ru(line, lower):\n",
    "    if lower:\n",
    "        line = line.lower()\n",
    "    line = re.sub(r\"[^\\w\\s-]|_\", ' ', line) # leave '-', remove '_'\n",
    "    \n",
    "    # Leave only one '-' in row:\n",
    "    \n",
    "    line = re.sub(\"--+\", ' ', line) # --\n",
    "    \n",
    "    line = ' ' + line + ' '\n",
    "    line = re.sub(r'-\\s|\\s-', ' ', line)  # leve '-' only inside words\n",
    "    \n",
    "    line = re.sub(r'\\s+', ' ', line)\n",
    "    return line.strip()\n",
    "\n",
    "\n",
    "\n",
    "class Lang(Enum):\n",
    "    EN = 1\n",
    "    RU = 2\n",
    "\n",
    "def _get_lang_idx(lang: Lang):\n",
    "    if lang == Lang.EN:\n",
    "        return 0\n",
    "    elif lang == Lang.RU:\n",
    "        return 1\n",
    "    else:\n",
    "        assert False, 'Unknown language ' + str(lang)\n",
    "\n",
    "def _str_preprocess(s: str, lang: Lang):\n",
    "    if lang == Lang.RU:\n",
    "        s = _remove_punc_ru(s, lower = True)\n",
    "    else:\n",
    "        s = _remove_punc_en(s, lower = True)\n",
    "    s = _get_reversed(s)\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "class Tokenizer(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 bpe_path: str,\n",
    "                 vocab_path: str,\n",
    "                 lang: Lang):\n",
    "\n",
    "        assert os.path.exists(bpe_path)\n",
    "        assert os.path.exists(vocab_path)\n",
    "\n",
    "        print('Loading {} tokenizer...'.format('English' if lang == Lang.EN else 'Russian'))\n",
    "        self._lang = lang\n",
    "        \n",
    "        print(' Loading BPE...')\n",
    "        self._bpe = _load_bpe(bpe_path, separator = '@')\n",
    "\n",
    "\n",
    "        print(' Reading vocabulary file...', flush = True)\n",
    "\n",
    "        tok_list = []\n",
    "        with _open_read_text(vocab_path) as voc_f:\n",
    "            for tok_line in tqdm(voc_f):\n",
    "                assert tok_line[-1] == '\\n'\n",
    "                tok_list.append(tok_line[:-1])\n",
    "\n",
    "        print(' token count: {}'.format(_count_to_str(len(tok_list))))\n",
    "\n",
    "        self._vocab = Vocab(regular_tokens = tok_list, reversed_ = True, chars = False)\n",
    "    \n",
    "    \n",
    "    def str_to_tok_ids(self, s: str):\n",
    "        s = _str_preprocess(s, self._lang)\n",
    "        toks = self._bpe.segment_tokens(s.split())\n",
    "        return self._vocab.tokens_to_ids(toks)\n",
    "    \n",
    "    def _tokens_str_to_str(self, s: str):\n",
    "        s = s.replace('@ ', '')\n",
    "        return _get_reversed(s)\n",
    "    \n",
    "    def tokens_to_str(self, tokens):\n",
    "        s = ' '.join(tokens)\n",
    "        s = s.replace('@ ', '')\n",
    "        return _get_reversed(s)\n",
    "    \n",
    "    def tok_ids_to_str(self, tok_ids: np.ndarray):\n",
    "        assert type(tok_ids) == np.ndarray, 'NDarray expected as \"tok_ids\"'\n",
    "        \n",
    "        return self._tokens_str_to_str(self._vocab.token_ids_to_str(tok_ids))\n",
    "    \n",
    "    \n",
    "    def tok_ids_seq_to_matrix(self, tok_ids_seq, max_matrix_width):\n",
    "        return self._vocab.tok_ids_seq_to_matrix(tok_ids_seq, max_matrix_width)\n",
    "    \n",
    "    def lines_to_matrix(self, lines, max_matrix_width):\n",
    "        \n",
    "        tok_ids_seq = [self.str_to_tok_ids(s) for s in lines]\n",
    "        return self.tok_ids_seq_to_matrix(tok_ids_seq, max_matrix_width)\n",
    "    \n",
    "    def matrix_to_lines(self, matrix: np.ndarray):\n",
    "        \"\"\"\n",
    "        Convert matrix of token ids into strings\n",
    "        :param matrix: matrix of tokens of int32, shape=[batch,time]\n",
    "        \"\"\"\n",
    "        lines = [self.tok_ids_to_str(tok_ids)\n",
    "                 for tok_ids in self._vocab.matrix_to_tok_ids_seq(matrix)]\n",
    "        return lines\n",
    "\n",
    "\n",
    "\n",
    "class EnRuDataset(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 src_bpe_path: str,\n",
    "                 tgt_bpe_path: str,\n",
    "                 src_vocab_path: str,\n",
    "                 tgt_vocab_path: str,\n",
    "                 train_dataset_tok_ids_path: str,\n",
    "                 dev_dataset_tok_ids_path: str,\n",
    "                 dev_dataset_toks_path: str):\n",
    "\n",
    "        assert os.path.exists(src_bpe_path)\n",
    "        assert os.path.exists(tgt_bpe_path)\n",
    "        assert os.path.exists(src_vocab_path)\n",
    "        assert os.path.exists(tgt_vocab_path)\n",
    "        assert os.path.exists(train_dataset_tok_ids_path)\n",
    "        assert os.path.exists(dev_dataset_tok_ids_path)\n",
    "        assert os.path.exists(dev_dataset_toks_path)\n",
    "\n",
    "\n",
    "        self._tokenizer_pair = [Tokenizer(bpe_path = src_bpe_path,\n",
    "                                          vocab_path = src_vocab_path,\n",
    "                                          lang = Lang.EN),\n",
    "                                \n",
    "                                Tokenizer(bpe_path = tgt_bpe_path,\n",
    "                                          vocab_path = tgt_vocab_path,\n",
    "                                          lang = Lang.RU)]\n",
    "\n",
    "\n",
    "        print('Reading train token ID lines...', flush = True)\n",
    "        self._train_tok_id_pairs = _load_tok_pairs(train_dataset_tok_ids_path, tok_ids = True)\n",
    "        print(' updating token IDs...', flush = True)\n",
    "        _update_tok_id_pairs(self._train_tok_id_pairs)\n",
    "\n",
    "        print('Reading dev token ID lines...', flush = True)\n",
    "        self._dev_tok_id_pairs = _load_tok_pairs(dev_dataset_tok_ids_path, tok_ids = True)\n",
    "        print(' updating token IDs...', flush = True)\n",
    "        _update_tok_id_pairs(self._dev_tok_id_pairs)\n",
    "\n",
    "        print('Reading dev token lines...', flush = True)\n",
    "        self._dev_tok_pairs = _load_tok_pairs(dev_dataset_toks_path, tok_ids = False)\n",
    "    \n",
    "    \n",
    "    def get_tokenizer(self, lang: Lang):\n",
    "        \n",
    "        return self._tokenizer_pair[_get_lang_idx(lang)]\n",
    "    \n",
    "    def _tokens_to_str(self, tokens):\n",
    "        s = ' '.join(tokens)\n",
    "        s = s.replace('@ ', '')\n",
    "        return _get_reversed(s)\n",
    "\n",
    "\n",
    "    def _to_matrix_pair(self, tok_ids_pairs, max_matrix_width):\n",
    "        tok_ids_seq_pair = zip(*tok_ids_pairs)\n",
    "        matrix_pair = [tokenizer.tok_ids_seq_to_matrix(tok_ids_seq, max_matrix_width) for tokenizer, tok_ids_seq\n",
    "                       in zip(self._tokenizer_pair, tok_ids_seq_pair)]\n",
    "        return tuple(matrix_pair)\n",
    "\n",
    "    def _iterate_minibatches(self, tok_id_pairs, tok_pairs, shuffle, batch_size, max_batch_matrix_width, epoch_count):\n",
    "\n",
    "        if tok_pairs is not None:\n",
    "            assert len(tok_id_pairs) == len(tok_pairs)\n",
    "            \n",
    "            def reversed_tok_seq(toks_seq):\n",
    "                return [self._tokens_to_str(toks) for toks in toks_seq]\n",
    "        \n",
    "        N = len(tok_id_pairs)\n",
    "        epoch = 0\n",
    "        while True:\n",
    "            if shuffle:\n",
    "                indices = np.random.permutation(np.arange(N))\n",
    "                for start in range(0, N, batch_size):\n",
    "                    batch_indices = indices[start : start + batch_size]\n",
    "                    matrix_pair = self._to_matrix_pair([tok_id_pairs[i] for i in batch_indices], max_batch_matrix_width)\n",
    "                    if tok_pairs is None:\n",
    "                        yield matrix_pair\n",
    "                    else:\n",
    "                        toks_seq_pair = tuple(zip(*[tok_pairs[i] for i in batch_indices]))\n",
    "                        yield matrix_pair, tuple(map(reversed_tok_seq, toks_seq_pair))\n",
    "            else:\n",
    "                for start in range(0, N, batch_size):\n",
    "                    matrix_pair = self._to_matrix_pair(tok_id_pairs[start : start + batch_size], max_batch_matrix_width)\n",
    "                    if tok_pairs is None:\n",
    "                        yield matrix_pair\n",
    "                    else:\n",
    "                        toks_seq_pair = tuple(zip(*tok_pairs[start : start + batch_size]))\n",
    "                        yield matrix_pair, tuple(map(reversed_tok_seq, toks_seq_pair))\n",
    "\n",
    "            epoch += 1\n",
    "            if epoch == epoch_count: # If epoch_count is 0 or None never terminate\n",
    "                break\n",
    "    \n",
    "    def iterate_train_minibatches(self, batch_size, max_batch_matrix_width, epoch_count, shuffle = True):\n",
    "        return self._iterate_minibatches(tok_id_pairs = self._train_tok_id_pairs,\n",
    "                                         tok_pairs = None,\n",
    "                                         shuffle = shuffle,\n",
    "                                         batch_size = batch_size,\n",
    "                                         max_batch_matrix_width = max_batch_matrix_width,\n",
    "                                         epoch_count = epoch_count)\n",
    "    \n",
    "    def iterate_dev_minibatches(self, batch_size, max_batch_matrix_width, epoch_count, shuffle = False):\n",
    "        return self._iterate_minibatches(tok_id_pairs = self._dev_tok_id_pairs,\n",
    "                                         tok_pairs = self._dev_tok_pairs,\n",
    "                                         shuffle = shuffle,\n",
    "                                         batch_size = batch_size,\n",
    "                                         max_batch_matrix_width = max_batch_matrix_width,\n",
    "                                         epoch_count = epoch_count)\n",
    "\n",
    "\n",
    "dataset = EnRuDataset(\n",
    "    src_bpe_path = train_bpe_en_path,\n",
    "    tgt_bpe_path = train_bpe_ru_path,\n",
    "    src_vocab_path = train_vocab_en_path,\n",
    "    tgt_vocab_path = train_vocab_ru_path,\n",
    "    train_dataset_tok_ids_path = train_dataset_tok_ids_path,\n",
    "    dev_dataset_tok_ids_path = dev_dataset_tok_ids_path,\n",
    "    dev_dataset_toks_path = dev_dataset_toks_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you you can do anything you want to|ты ты можешь делать всё что хочешь\n",
      "you you can do anything       |ты ты можешь делать что угодно\n",
      "yeah i'm coming home again    |да я снова возвращаюсь домой\n",
      "to you                        |к тебе\n",
      "cuz you're my only friend     |ведь ты мой единственный друг\n",
      "i'll lean into the spirit's hands|я вверю себя в руки святого духа\n",
      "believe                       |вновь\n",
      "in trinity again              |поверю в троицу\n",
      "like it'll never end          |словно этому не будет конца\n",
      "black stars                   |чёрные звезды\n",
      "\n",
      "ma'ma mila ramu\n",
      "ма ма мыла раму\n"
     ]
    }
   ],
   "source": [
    "en_tokenizer = dataset.get_tokenizer(Lang.EN)\n",
    "ru_tokenizer = dataset.get_tokenizer(Lang.RU)\n",
    "\n",
    "for src_tok_ids, tgt_tok_ids in dataset._train_tok_id_pairs[:10]:\n",
    "    print('{:30}|{}'.format(en_tokenizer.tok_ids_to_str(src_tok_ids),\n",
    "                            ru_tokenizer.tok_ids_to_str(tgt_tok_ids)))\n",
    "print()\n",
    "print(en_tokenizer.tok_ids_to_str(en_tokenizer.str_to_tok_ids('Ma\\'ma mila ramu!')))\n",
    "print(ru_tokenizer.tok_ids_to_str(ru_tokenizer.str_to_tok_ids('Ма\\'ма мыла раму!')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"it's a desert out there\", 'people running scared', 'looking everywhere for hope']\n",
      "['там пустыня', 'и люди разбегаются в страхе', 'в поисках опоры']\n",
      "CPU times: user 2.14 s, sys: 44 ms, total: 2.18 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dev_src_lines = []\n",
    "dev_tgt_lines = []\n",
    "for (src_matrix, tgt_matrix), (src_lines, tgt_lines) in dataset.iterate_dev_minibatches(max_batch_matrix_width = None,\n",
    "                                                                                        batch_size = 1000,\n",
    "                                                                                        epoch_count = 1):\n",
    "    dev_src_lines += src_lines\n",
    "    dev_tgt_lines += tgt_lines\n",
    "\n",
    "assert len(dev_src_lines) == len(dev_tgt_lines) == len(dataset._dev_tok_id_pairs)\n",
    "\n",
    "print(dev_src_lines[:3])\n",
    "print(dev_tgt_lines[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonnet generally consists of 14 lines but some of them more, like 15 in this Shakeapeare sonnet:\n",
    "\n",
    "```\n",
    "The forward violet thus did I chide,\n",
    "Sweet thief, whence didst thou steal thy sweet that smells,\n",
    "If not from my love’s breath? The purple pride\n",
    "Which on thy soft check for complexion dwells,\n",
    "In my love’s veins thou hast too grossly dyed.\n",
    "The lily I condemned for thy hand,\n",
    "And buds of marjoram had stol’n thy hair,\n",
    "The roses fearfully on thorns did stand,\n",
    "One blushing shame, another white despair:\n",
    "A third nor red, nor white, had stol’n of both,\n",
    "And to his robbery had annexed thy breath,\n",
    "But for his theft in pride of all his growth\n",
    "A vengeful canker eat him up to death.\n",
    "More flowers I noted, yet I none could see,\n",
    "But sweet, or colour it had stol’n from thee.```\n",
    "\n",
    "We will drop such sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sonnet_lines_english) 2128\n",
      "len(sonnet_lines_russian) 2128\n",
      "non_fourteen_lines 2\n",
      "Why lov’st thou that which thou receiv’st not gladly,\n",
      "Зачем же любишь то, что так печально,\n",
      "When I perceive that men as plants increase,\n",
      "Что нас, как всходы нежные растений,\n",
      "------------------\n",
      "но вижу я в твоих глазах предвестье\n",
      "уверенность и власть греховных сил\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_sonnets_lines_parallel(fname):\n",
    "    sonnet_lines_english = []\n",
    "    sonnet_lines_russian = []\n",
    "    non_fourteen_lines = 0\n",
    "    with open(fname, mode = 'r', encoding = 'utf-8') as f:\n",
    "        sonnets = f.read().replace('\\r', '').split('\\n===\\n')\n",
    "    for sonnet in sonnets:\n",
    "        en, ru = sonnet.split('\\n---\\n')\n",
    "        en = [line.strip() for line in en.split('\\n') if line.strip() != '']\n",
    "        ru = [line.strip() for line in ru.split('\\n') if line.strip() != '']\n",
    "        if len(en) != 14 or len(ru) != 14:\n",
    "            non_fourteen_lines += 1\n",
    "            continue\n",
    "        sonnet_lines_english.extend(en)\n",
    "        sonnet_lines_russian.extend(ru)\n",
    "    assert len(sonnet_lines_english) == len(sonnet_lines_russian)\n",
    "    return sonnet_lines_english, sonnet_lines_russian, non_fourteen_lines\n",
    "\n",
    "import re\n",
    "def remove_punc_and_lower(line, lang):\n",
    "    if lang == Lang.RU:\n",
    "        return _remove_punc_ru(line, lower = True)\n",
    "    else:\n",
    "        return _remove_punc_en(line, lower = True)\n",
    "\n",
    "(sonnet_lines_english,\n",
    " sonnet_lines_russian,\n",
    " non_fourteen_lines) = \\\n",
    "get_sonnets_lines_parallel(SHAKESPEARE_SONNETS_PARALLEL_PATH)\n",
    "print('len(sonnet_lines_english)', len(sonnet_lines_english))\n",
    "print('len(sonnet_lines_russian)', len(sonnet_lines_russian))\n",
    "print('non_fourteen_lines', non_fourteen_lines)\n",
    "print(sonnet_lines_english[100])\n",
    "print(sonnet_lines_russian[100])\n",
    "print(sonnet_lines_english[200])\n",
    "print(sonnet_lines_russian[200])\n",
    "\n",
    "(train_sonnet_lines_english,\n",
    " dev_sonnet_lines_english,\n",
    " train_sonnet_lines_russian,\n",
    " dev_sonnet_lines_russian) = train_test_split([remove_punc_and_lower(line, Lang.EN) for \\\n",
    "                                               line in sonnet_lines_english],\n",
    "                                              [remove_punc_and_lower(line, Lang.RU) for \\\n",
    "                                               line in sonnet_lines_russian],\n",
    "                                              test_size = 0.15,\n",
    "                                              random_state = 1)\n",
    "print('------------------')\n",
    "print(train_sonnet_lines_russian[0])\n",
    "print(dev_sonnet_lines_russian[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, some lines don't correspond to -+-+-+-+-+ pattern but correspond to -+-+-+-+-+-\n",
    "\n",
    "Let us try to filter out non-10 syllables lines and see how much lines will remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808\n",
      "320\n",
      "1184\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "def count_syllables_russian(line):\n",
    "    vowels = 'аеёиоуыэюяАЕЁИОУЫЭЮЯ'\n",
    "    return len([c for c in line if c in vowels])\n",
    "\n",
    "train_sonnet_lines_russian_ten_syllables = \\\n",
    "[line for line in train_sonnet_lines_russian if \\\n",
    " count_syllables_russian(line) == 10]\n",
    "\n",
    "dev_sonnet_lines_russian_ten_syllables = \\\n",
    "[line for line in dev_sonnet_lines_russian if \\\n",
    " count_syllables_russian(line) == 10]\n",
    "\n",
    "print(len(train_sonnet_lines_russian))\n",
    "print(len(dev_sonnet_lines_russian))\n",
    "print(len(train_sonnet_lines_russian_ten_syllables))\n",
    "print(len(dev_sonnet_lines_russian_ten_syllables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too little lines remain if we filter them by syllables count thus let us not filter them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sonnet_lines_russian_stresses = \\\n",
    "[[i % 2 == 1 for i in range(count_syllables_russian(line))] \\\n",
    " for line in train_sonnet_lines_russian]\n",
    "dev_sonnet_lines_russian_stresses = \\\n",
    "[[i % 2 == 1 for i in range(count_syllables_russian(line))] \\\n",
    " for line in dev_sonnet_lines_russian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=4\n",
    "import tensorflow as tf\n",
    "import keras.layers as L\n",
    "from keras import backend as K\n",
    "from utils import infer_length, infer_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ITranslationModel(object):\n",
    "\n",
    "    def make_initial_state(self, lines):\n",
    "        '''\n",
    "        Accepts array of lines.\n",
    "        Returns initial translation state for lines.\n",
    "        '''\n",
    "        raise Exception('Not implemented')\n",
    "    \n",
    "    def get_next_state_and_logits(self, state, outputs):\n",
    "        '''\n",
    "        Accepts current translation state and model outputs.\n",
    "        Returns next translation state and logits.\n",
    "        '''\n",
    "        raise Exception('Not implemented')\n",
    "    \n",
    "    def get_output_vocabulary(self):\n",
    "        '''\n",
    "        Return output vocabulary used in model.\n",
    "        '''\n",
    "        raise Exception('Not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharVocab(Vocab):\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"\n",
    "        A special class that converts lines of tokens into matrices and backwards\n",
    "        \"\"\"\n",
    "        Vocab.__init__(self,\n",
    "                       regular_tokens = chars,\n",
    "                       reversed_ = True,\n",
    "                       chars = True)\n",
    "\n",
    "    def tokenize(self, string):\n",
    "        \"\"\"converts string to a list of tokens\"\"\"\n",
    "        tokens = [ch if ch in self.token_to_ix else self.unk\n",
    "                  for ch in string]\n",
    "        return [self.bos] + tokens + [self.eos]\n",
    "    \n",
    "    def str_to_tok_ids(self, string):\n",
    "        \n",
    "        token_ids = [self.token_to_ix.get(ch, self.unk_ix) for ch in string]\n",
    "        return [self.bos_ix] + token_ids + [self.eos_ix]\n",
    "    \n",
    "    def lines_to_matrix(self, lines, max_matrix_width):\n",
    "        \n",
    "        tok_ids_seq = [self.str_to_tok_ids(s) for s in lines]\n",
    "        return self.tok_ids_seq_to_matrix(tok_ids_seq, max_matrix_width)\n",
    "\n",
    "    def tok_matrix_to_char_matrix(self, tok_voc, tok_matrix, max_tok_len = 10):\n",
    "        # input: tok_matrix is numpy array of shape (n_lines, >=max_doc_len_in_bpe_tokens)\n",
    "        # input example for tok_voc.tokens = {101: 'a', 102: 'abc', 103: 'ca', ...}:\n",
    "        # [[101, 102]\n",
    "        #  [103, <eos>]]\n",
    "        # output_example for self.tokens = {1: 'a', 2: 'b', 3: 'c', ...}:\n",
    "        # [[[1, <eos>, <eos>], [1, 2, 3]]\n",
    "        #  [[3, 1, , <eos>], [<eos>, <eos>, <eos>]]]\n",
    "        assert tok_matrix.ndim == 2\n",
    "        \n",
    "        get_tok_str = lambda tok: tok_voc.tokens[tok] if tok != tok_voc.eos_ix else ''\n",
    "        \n",
    "        max_len = max(map(lambda tok: len(get_tok_str(tok)), tok_matrix.flatten())) + 2\n",
    "        if max_tok_len is not None and max_len > max_tok_len:\n",
    "            max_len = max_tok_len\n",
    "        assert max_len >= 2\n",
    "        \n",
    "        matrix = np.full(tok_matrix.shape + (max_len,),\n",
    "                         fill_value = self.eos_ix,\n",
    "                         dtype = np.int32)\n",
    "        \n",
    "        for i, tok_seq in enumerate(tok_matrix):\n",
    "            for j, tok in enumerate(tok_seq):\n",
    "                tok_str = get_tok_str(tok)[:max_len - 2]\n",
    "                matrix[i, j, :len(tok_str) + 2] = self.str_to_tok_ids(tok_str)\n",
    "\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_type_full_name(t):\n",
    "    assert isinstance(t, type)\n",
    "    res = t.__qualname__\n",
    "    if t.__module__ not in ('builtins', '__main__'):\n",
    "        res = t.__module__ + '.' + res\n",
    "    return res\n",
    "\n",
    "class ConfigBase(object):\n",
    "\n",
    "    def __init__(self, cfg, user_args, **kwargs):\n",
    "        # We need this class to avoid passing\n",
    "        # too many params in model classes initializers\n",
    "        # Example usage:\n",
    "        #    class MyConfig(ConfigBase):\n",
    "        #        def __init__(self, **kwargs):\n",
    "        #            super().__init__(self,\n",
    "        #                             user_args = kwargs,\n",
    "        #                             emb_size = None,\n",
    "        #                             hid_size = None,\n",
    "        #                             dropout_prob = None)\n",
    "        #\n",
    "        #    my_config = MyConfig(emb_size = 150,\n",
    "        #                         hid_size = 50,\n",
    "        #                         dropout_prob = 0)\n",
    "        \n",
    "        for key, user_val in user_args.items():\n",
    "            assert key in kwargs, 'Unknown field \"{}\" with value \"{}\"'.format(key, user_val)\n",
    "            assert user_val is not None, 'Field \"{}\" can\\'t have \"None\" value'.format(key)\n",
    "            \n",
    "            default_val = kwargs[key]\n",
    "            is_subconfig = isinstance(default_val, type) and issubclass(default_val, ConfigBase)\n",
    "            \n",
    "            if isinstance(user_val, ConfigBase):\n",
    "                assert is_subconfig, \\\n",
    "                       'Field \"{}\" is not a sub-config and can\\'t be set with config \"{}\"' \\\n",
    "                       .format(key, get_type_full_name(type(user_val)))\n",
    "                assert type(user_val) == default_val, \\\n",
    "                       'Sub-config \"{}\" must have type \"{}\", instead \"{}\" given' \\\n",
    "                       .format(key, get_type_full_name(default_val), get_type_full_name(type(user_val)))\n",
    "            elif is_subconfig:\n",
    "                assert isinstance(user_val, dict), \\\n",
    "                       'Sub-config \"{}\" of type \"{}\" can only be created from dict, not \"{}\" of type \"{}\"' \\\n",
    "                       .format(key, get_type_full_name(default_val), user_val, get_type_full_name(type(user_val)))\n",
    "                user_val = default_val(**user_val)\n",
    "            \n",
    "            kwargs[key] = user_val\n",
    "            \n",
    "        for key, user_val in kwargs.items():\n",
    "            assert user_val is not None, 'Field \"{}\" without default value is not set'.format(key)\n",
    "            setattr(cfg, key, user_val)\n",
    "        \n",
    "        self._keys = list(kwargs.keys())\n",
    "    \n",
    "    def as_dict(self):\n",
    "        res = {key: getattr(self, key) for key in self._keys}\n",
    "        for key in self._keys:\n",
    "            if isinstance(res[key], ConfigBase):\n",
    "                res[key] = res[key].as_dict()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scope_trainable_variables(sub_scope_name = None):\n",
    "    full_scope_name = tf.get_variable_scope().name\n",
    "    if full_scope_name != '':\n",
    "        full_scope_name += '/'\n",
    "    if sub_scope_name is not None:\n",
    "        full_scope_name += sub_scope_name + '/'\n",
    "    return tf.trainable_variables(scope = re.escape(full_scope_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.layers as L\n",
    "from keras import backend as K\n",
    "from utils import infer_length, infer_mask\n",
    "\n",
    "\n",
    "class AttentionLayer:\n",
    "    \n",
    "    def __init__(self, name, hid_size, activ=tf.tanh):\n",
    "        \"\"\" A layer that computes additive attention response and weights \"\"\"\n",
    "        self.name = name\n",
    "        self.hid_size = hid_size # attention layer hidden units\n",
    "        self.activ = activ       # attention layer hidden nonlinearity\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            # YOUR CODE - create layer variables\n",
    "            #<YOUR CODE>\n",
    "            self.linear_e = L.Dense(hid_size)\n",
    "            self.linear_d = L.Dense(hid_size)\n",
    "            self.linear_out = L.Dense(1)\n",
    "\n",
    "    def __call__(self, enc, dec, inp_mask):\n",
    "        \"\"\"\n",
    "        Computes attention response and weights\n",
    "        :param enc: encoder activation sequence, float32[batch_size, ninp, enc_size]\n",
    "        :param dec: single decoder state used as \"query\", float32[batch_size, dec_size]\n",
    "        :param inp_mask: mask on enc activatons (0 after first eos), float32 [batch_size, ninp]\n",
    "        :returns: attn[batch_size, enc_size], probs[batch_size, ninp]\n",
    "            - attn - attention response vector (weighted sum of enc)\n",
    "            - probs - attention weights after softmax\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(self.name):\n",
    "            \n",
    "            # Compute logits\n",
    "            #<...>\n",
    "            logits_seq = self.linear_out(self.activ(self.linear_e(enc) + \\\n",
    "                                                    self.linear_d(dec)[:, tf.newaxis, :]))\n",
    "            logits_seq = tf.squeeze(logits_seq, axis = -1)\n",
    "            \n",
    "            # Apply mask - if mask is 0, logits should be -inf or -1e9\n",
    "            # You may need tf.where\n",
    "            #<...>\n",
    "            \n",
    "            logits_seq = tf.where(inp_mask, logits_seq, tf.fill(tf.shape(logits_seq),\n",
    "                                                                -np.inf))\n",
    "            \n",
    "            # Compute attention probabilities (softmax)\n",
    "            probs = tf.nn.softmax(logits_seq) # <...>\n",
    "            \n",
    "            # Compute attention response using enc and probs\n",
    "            attn = tf.reduce_sum(probs[..., tf.newaxis] * enc, axis = 1) # <...>\n",
    "            \n",
    "            return attn, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RuCharEncoder:\n",
    "    # This class is needed to create chr representation,\n",
    "    # which is, like in DeepSpeare,\n",
    "    # shareable between translator and meter models\n",
    "    \n",
    "    class Config(ConfigBase):\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(self,\n",
    "                             kwargs,\n",
    "                             emb_size = None,\n",
    "                             hid_size = None,\n",
    "                             dropout_prob = None)\n",
    "    \n",
    "    deepspeare_en_config = Config(emb_size = 150,  # as 'char_embedding_dim'\n",
    "                                  hid_size = 50,   # as 'pm_enc_dim'\n",
    "                                  #dropout_prob = 1 - 0.7) # as 'keep_prob'\n",
    "                                  dropout_prob = 0) # to show proper BLEU\n",
    "    \n",
    "    def __init__(self, name, config, is_training):\n",
    "        # ToDo: deal with 'is_training'\n",
    "        \n",
    "        assert type(name) == str\n",
    "        assert type(config) == RuCharEncoder.Config\n",
    "\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "        \n",
    "        ru_vowels = ['а', 'е', 'ё', 'и', 'о', 'у', 'ы', 'э', 'ю', 'я']\n",
    "        ru_other_letters = [chr(n) for n in range(ord('а'), ord('я') + 1) if chr(n) not in ru_vowels]\n",
    "        vocab = CharVocab(chars = ru_vowels + ru_other_letters + [' ', '@'])\n",
    "        self.space_idx = vocab.token_to_ix[' ']\n",
    "        self.tok_concat_idx = vocab.token_to_ix['@']\n",
    "        self._vowel_max_idx = len(ru_vowels) - 1\n",
    "        self._ru_char_voc = vocab\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            self._inp = tf.placeholder(tf.int32, [None, None])\n",
    "            \n",
    "            self._emb_inp = L.Embedding(len(self._ru_char_voc), config.emb_size)\n",
    "            \n",
    "            # In original DeepSpeare code they use the same LSTM Cell\n",
    "            # for both directions\n",
    "            # Maybe it's better to use two separate cells:\n",
    "            #self._enc_lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(config.hid_size)\n",
    "            #self._enc_lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(config.hid_size)\n",
    "            \n",
    "            enc_cell = tf.nn.rnn_cell.LSTMCell(config.hid_size)\n",
    "            if is_training and config.dropout_prob > 0:\n",
    "                enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob = 1 - config.dropout_prob)\n",
    "                \n",
    "            self._enc_lstm_fw_cell = enc_cell\n",
    "            self._enc_lstm_bw_cell = enc_cell\n",
    "            \n",
    "            self._enc_seq, self._en_last_hid = self.encode(self._inp)\n",
    "            \n",
    "            self.trainable_variables = get_scope_trainable_variables()\n",
    "\n",
    "    def lines_to_char_matrix(self, lines, max_matrix_width = 100):\n",
    "        return self._ru_char_voc.lines_to_matrix(lines, max_matrix_width = max_matrix_width)\n",
    "            \n",
    "    def tok_matrix_to_char_matrix(self, tok_voc, tok_matrix, max_tok_len = 10):\n",
    "        return self._ru_char_voc.tok_matrix_to_char_matrix(tok_voc, tok_matrix, max_tok_len)\n",
    "            \n",
    "    def vowel_mask(self, inp):\n",
    "        return inp <= self._vowel_max_idx\n",
    "    \n",
    "    def make_input_feed_dict(self, inp_lines):\n",
    "        return { self._inp: self._ru_char_voc.lines_to_matrix(inp_lines, max_matrix_width = None) }\n",
    "    \n",
    "    def get_input(self):\n",
    "        return self._inp\n",
    "    \n",
    "    def get_eos_ix(self):\n",
    "        return self._ru_char_voc.eos_ix\n",
    "    \n",
    "    def get_encoded_seq(self):\n",
    "        return self._enc_seq\n",
    "    \n",
    "    def get_encoded_last_hid(self):\n",
    "        return self._en_last_hid\n",
    "    \n",
    "    def encode(self, inp):\n",
    "        '''\n",
    "        Return tuple:\n",
    "        res[0]: encode seq, float32[batch_size, max_time, cfg.hid_size * 2]\n",
    "        res[1]: encode last hidden state, float32[batch_size, cfg.hid_size * 2]\n",
    "        '''\n",
    "        assert inp.shape.ndims == 2 # [batch_size, max_time]\n",
    "        \n",
    "        inp_lengths = infer_length(inp, self._ru_char_voc.eos_ix)\n",
    "        \n",
    "        inp_emb = self._emb_inp(inp)\n",
    "        with tf.variable_scope('enc'):\n",
    "            ((enc_seq_fw,\n",
    "              enc_seq_bw),\n",
    "             (enc_last_fw,\n",
    "              enc_last_bw)) = tf.nn.bidirectional_dynamic_rnn(self._enc_lstm_fw_cell,\n",
    "                                                              self._enc_lstm_bw_cell,\n",
    "                                                              inp_emb,\n",
    "                                                              sequence_length = inp_lengths,\n",
    "                                                              dtype = inp_emb.dtype)\n",
    "        enc_seq = tf.concat((enc_seq_fw, enc_seq_bw), axis = -1)\n",
    "        enc_last_hid = tf.concat((enc_last_fw[1], enc_last_bw[1]), axis = -1)\n",
    "        return enc_seq, enc_last_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer_length_exclude_eos(seq, eos_ix, dtype=tf.int32):\n",
    "    is_eos = tf.cast(tf.equal(seq, eos_ix), dtype)\n",
    "    count_eos = tf.cumsum(is_eos,axis=1,exclusive=False)\n",
    "    lengths = tf.reduce_sum(tf.cast(tf.equal(count_eos,0),dtype),axis=1)\n",
    "    return lengths\n",
    "\n",
    "class MeterModel:\n",
    "    # Neural architecture of meter model\n",
    "    # and most of code\n",
    "    # are borrowed from DeepSpeare Pentameter model\n",
    "\n",
    "    class Config(ConfigBase):\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(self,\n",
    "                             kwargs,\n",
    "                             max_out_length = None,\n",
    "                             # From deepspeare code:\n",
    "                             dropout_prob = None,\n",
    "                             pm_dec_dim = None,\n",
    "                             max_grad_norm = None,\n",
    "                             pm_learning_rate = None,\n",
    "                             pm_attend_dim = None,\n",
    "                             sigma = None,\n",
    "                             cov_loss_threshold = None,\n",
    "                             repeat_loss_scale = None,\n",
    "                             cov_loss_scale = None)\n",
    "            \n",
    "    deepspeare_config = Config(max_out_length = 15,\n",
    "                               # From deepspeare code:\n",
    "                               #dropout_prob = 1 - 0.7, # as 'keep_prob'\n",
    "                               dropout_prob = 0, # to show proper BLEU\n",
    "                               pm_dec_dim=200,\n",
    "                               pm_attend_dim=50,\n",
    "                               pm_learning_rate=0.001,\n",
    "                               repeat_loss_scale=1.0,\n",
    "                               cov_loss_scale=1.0,\n",
    "                               cov_loss_threshold=0.7,\n",
    "                               sigma=1.00,\n",
    "                               max_grad_norm=5)\n",
    "    \n",
    "    def __init__(self, name, config, batch_size, is_training, ru_char_encoder):\n",
    "        \n",
    "        assert type(name) == str\n",
    "        assert type(config) == MeterModel.Config\n",
    "\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "\n",
    "        self._ru_char_encoder = ru_char_encoder\n",
    "        self._stress_eos_ix = -1\n",
    "\n",
    "        cfg = self.config\n",
    "        cfg_pm_enc_dim = ru_char_encoder.config.hid_size\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            self._out = tf.placeholder(tf.int32, [None, None])\n",
    "\n",
    "            dec_cell = tf.nn.rnn_cell.LSTMCell(cfg.pm_dec_dim)\n",
    "            #if is_training and cfg.dropout_prob > 0:\n",
    "            #    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob = 1 - cfg.dropout_prob)\n",
    "\n",
    "            enc_hiddens = ru_char_encoder.get_encoded_seq()\n",
    "            enc_hiddens  = tf.reshape(enc_hiddens, [-1, cfg_pm_enc_dim*2]) #[batch_size*num_steps, hidden]\n",
    "                    \n",
    "            #if not is_training:\n",
    "            self.pm_costs     = self.compute_pm_loss(batch_size = batch_size,\n",
    "                                                     enc_hiddens = enc_hiddens,\n",
    "                                                     dec_cell = dec_cell)\n",
    "            self.pm_mean_cost = tf.reduce_sum(self.pm_costs) / batch_size\n",
    "            \n",
    "            self.trainable_variables = get_scope_trainable_variables() + \\\n",
    "                                       ru_char_encoder.trainable_variables\n",
    "\n",
    "        if is_training:\n",
    "            #run optimiser and backpropagate (clipped) gradients for pm loss\n",
    "            pm_tvars         = self.trainable_variables\n",
    "            pm_grads, _      = tf.clip_by_global_norm(tf.gradients(self.pm_mean_cost, pm_tvars),\n",
    "                                                      cfg.max_grad_norm)\n",
    "            self.pm_train_op = tf.train.AdamOptimizer(cfg.pm_learning_rate).apply_gradients(zip(pm_grads, pm_tvars))\n",
    "    \n",
    "    def get_input(self):\n",
    "        return self._ru_char_encoder.get_input()\n",
    "    \n",
    "    def get_output(self):\n",
    "        return self._out\n",
    "    \n",
    "    def to_stress_matrix(self, stress_lines):\n",
    "        \n",
    "        max_len = min(self.config.max_out_length, max(map(len, stress_lines)))\n",
    "\n",
    "        matrix = np.full((len(stress_lines), max_len), fill_value = self._stress_eos_ix, dtype = np.int32)\n",
    "        for i, stresses in enumerate(stress_lines):\n",
    "            stresses = stresses[:max_len]\n",
    "            matrix[i, :len(stresses)] = stresses\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    # -- compute pentameter model loss, given a pentameter input\n",
    "    # It may seem strange that we pass dec_cell here despite it is \n",
    "    def compute_pm_loss(self, batch_size, enc_hiddens, dec_cell):\n",
    "        \n",
    "        # Note: Deepspeare uses old TensorFlow API where tf.concat accepts axis first like: tf.concat(1, [t1, t2])\n",
    "        # So, here it is changed to new TF style: tf.concat([t1, t2], axis = 1)\n",
    "\n",
    "        cfg = self.config\n",
    "        cfg_pm_enc_dim = self._ru_char_encoder.config.hid_size\n",
    "\n",
    "        space_id = self._ru_char_encoder.space_idx\n",
    "\n",
    "        inp = self.get_input()\n",
    "        out = self.get_output()\n",
    "        out_len = infer_length_exclude_eos(out, self._stress_eos_ix)\n",
    "        max_out_len = tf.shape(out)[1]\n",
    "        out_mask = tf.sequence_mask(out_len, maxlen = max_out_len, dtype = tf.float32)\n",
    "\n",
    "        eos_ix = self._ru_char_encoder.get_eos_ix()\n",
    "        inp_lengths = infer_length(inp, eos_ix)\n",
    "        inp_mask = infer_mask(inp, eos_ix, dtype = tf.bool)\n",
    "        pm_cov_mask = tf.cast(self._ru_char_encoder.vowel_mask(inp) & inp_mask, dtype = tf.float32)\n",
    "        #xlen_max       = tf.reduce_max(inp_lengths) # Logic in Deepspeare\n",
    "        xlen_max       = tf.shape(inp)[1] # Our current logic\n",
    "\n",
    "        #use decoder hidden states to select encoder hidden states to predict stress for next time step\n",
    "        repeat_loss    = tf.zeros([batch_size])\n",
    "        attentions     = tf.zeros([batch_size, xlen_max]) #historical attention weights\n",
    "        prev_miu       = tf.zeros([batch_size,1])\n",
    "        outputs        = []\n",
    "        attention_list = []\n",
    "        miu_list       = []\n",
    "\n",
    "        #initial inputs (learnable) and state\n",
    "        initial_inputs = tf.get_variable(\"dec_init_input\", [cfg_pm_enc_dim*2])\n",
    "        inputs         = tf.reshape(tf.tile(initial_inputs, [batch_size]), [batch_size, -1])\n",
    "        state          = dec_cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        #manual unroll of time steps because attention depends on previous attention weights\n",
    "        with tf.variable_scope(\"RNN\"):\n",
    "            for time_step in range(cfg.max_out_length):\n",
    "\n",
    "                if time_step > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                def attend(enc_hiddens, dec_hidden, attn_hist, prev_miu):\n",
    "                    with tf.variable_scope(\"pm_attention\"):\n",
    "                        attend_w = tf.get_variable(\"attend_w\", [cfg_pm_enc_dim*2+cfg.pm_dec_dim, cfg.pm_attend_dim])\n",
    "                        attend_b = tf.get_variable(\"attend_b\", [cfg.pm_attend_dim], initializer=tf.constant_initializer())\n",
    "                        attend_v = tf.get_variable(\"attend_v\", [cfg.pm_attend_dim, 1])\n",
    "                        miu_w    = tf.get_variable(\"miu_w\", [cfg.pm_dec_dim+1, cfg.pm_attend_dim])\n",
    "                        miu_b    = tf.get_variable(\"miu_b\", [cfg.pm_attend_dim], initializer=tf.constant_initializer())\n",
    "                        miu_v    = tf.get_variable(\"miu_v\", [cfg.pm_attend_dim, 1])\n",
    "\n",
    "                    #position attention\n",
    "                    miu     = tf.minimum(tf.sigmoid(tf.matmul(tf.tanh(tf.matmul(tf.concat(\n",
    "                        [dec_hidden, prev_miu], axis = 1), miu_w) + miu_b), miu_v)) + prev_miu, tf.ones([batch_size, 1]))\n",
    "                    miu_p   = miu * tf.reshape(tf.cast(inp_lengths-1, tf.float32), [-1, 1])\n",
    "                    pos     = tf.cast(tf.reshape(tf.tile(tf.range(xlen_max), [batch_size]), [batch_size, -1]),\n",
    "                        dtype=tf.float32)\n",
    "                    pos_lp  = -(pos - miu_p)**2 / (2 * tf.reshape(tf.tile([tf.square(cfg.sigma)], [batch_size]),\n",
    "                        [batch_size,-1]))\n",
    "\n",
    "                    #char encoding attention\n",
    "                    pos_weight = tf.reshape(tf.exp(pos_lp), [-1, 1])\n",
    "                    inp_concat = tf.concat([enc_hiddens * pos_weight,\n",
    "                        tf.reshape(tf.tile(dec_hidden, [1,xlen_max]), [-1,cfg.pm_dec_dim])], axis = 1)\n",
    "                    x       = inp\n",
    "                    e       = tf.matmul(tf.tanh(tf.matmul(inp_concat, attend_w) + attend_b), attend_v)\n",
    "                    e       = tf.reshape(e, [batch_size, xlen_max])\n",
    "                    mask1   = tf.cast(~inp_mask, dtype=tf.float32)\n",
    "                    mask2   = tf.cast(tf.equal(x, tf.fill(tf.shape(x), space_id)), dtype=tf.float32)\n",
    "                    e_mask  = tf.maximum(mask1, mask2)\n",
    "                    e_mask *= tf.constant(-1e20)\n",
    "\n",
    "                    #combine alpha with position probability\n",
    "                    alpha   = tf.nn.softmax(e + e_mask + pos_lp)\n",
    "                    #alpha   = tf.nn.softmax(e + e_mask)\n",
    "\n",
    "                    #weighted sum\n",
    "                    c       = tf.reduce_sum(tf.expand_dims(alpha, 2)*tf.reshape(enc_hiddens,\n",
    "                        [batch_size, xlen_max, cfg_pm_enc_dim*2]), 1)\n",
    "\n",
    "                    return c, alpha, miu\n",
    "\n",
    "                dec_hidden, state               = dec_cell(inputs, state)\n",
    "                enc_hiddens_sum, attn, prev_miu = attend(enc_hiddens, dec_hidden, attentions, prev_miu)\n",
    "\n",
    "                # Zero 'attn' if past end of output:\n",
    "                valid_step = time_step < out_len\n",
    "                attn *= tf.cast(valid_step, tf.float32)[:, tf.newaxis]\n",
    "                \n",
    "                repeat_loss += tf.reduce_sum(tf.minimum(attentions, attn), 1)\n",
    "                attentions  += attn\n",
    "                inputs       = enc_hiddens_sum\n",
    "\n",
    "                attention_list.append(attn)\n",
    "                miu_list.append(prev_miu)\n",
    "                outputs.append(enc_hiddens_sum)\n",
    "\n",
    "        #reshape output into [batch_size*num_steps,hidden_size]\n",
    "        #outputs = tf.reshape(tf.concat(outputs, axis = 1), [-1, cfg_pm_enc_dim*2]) # Original code\n",
    "        outputs = tf.concat(outputs, axis = 1)\n",
    "        outputs = outputs[:, :max_out_len * cfg_pm_enc_dim*2] # Also truncate outputs\n",
    "        outputs = tf.reshape(outputs, [-1, cfg_pm_enc_dim*2])\n",
    "        \n",
    "\n",
    "        #compute loss\n",
    "        pm_softmax_w = tf.get_variable(\"pm_softmax_w\", [cfg_pm_enc_dim*2, 1])\n",
    "        pm_softmax_b = tf.get_variable(\"pm_softmax_b\", [1], initializer=tf.constant_initializer())\n",
    "        #pm_logit     = tf.squeeze(tf.matmul(outputs, pm_softmax_w) + pm_softmax_b) # Original code\n",
    "        pm_logit     = tf.reshape(tf.matmul(outputs, pm_softmax_w) + pm_softmax_b, [batch_size, -1])\n",
    "        pm_crossent  = tf.nn.sigmoid_cross_entropy_with_logits(logits = pm_logit,\n",
    "            #labels = tf.tile(tf.cast(fixed_out, tf.float32), [batch_size])) # Original code\n",
    "            labels = tf.cast(out, tf.float32))\n",
    "        pm_crossent *= out_mask # Addition: Mask out past-end output\n",
    "        cov_loss     = tf.reduce_sum(tf.nn.relu(pm_cov_mask*cfg.cov_loss_threshold - attentions), 1)\n",
    "        #pm_cost      = tf.reduce_sum(tf.reshape(pm_crossent, [batch_size, -1]), 1) + \\ # Original code\n",
    "        # No need to reshape 'pm_crossent' now:\n",
    "        pm_cost      = tf.reduce_sum(pm_crossent, 1) + \\\n",
    "            cfg.repeat_loss_scale*repeat_loss + cfg.cov_loss_scale*cov_loss\n",
    "\n",
    "        #save some variables\n",
    "        self.pm_logits     = tf.sigmoid(tf.reshape(pm_logit, [batch_size, -1]))\n",
    "        self.pm_attentions = attention_list\n",
    "        self.mius          = miu_list\n",
    "\n",
    "        return pm_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentiveModel(ITranslationModel):\n",
    "    \n",
    "    class Config(ConfigBase):\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(self,\n",
    "                             kwargs,\n",
    "                             batch_size = None,\n",
    "                             emb_size = None,\n",
    "                             hid_size = None,\n",
    "                             #attn_size = None,\n",
    "                             ru_char_encoder_config = RuCharEncoder.Config,\n",
    "                             meter_config = MeterModel.Config)\n",
    "    \n",
    "    def __init__(self, sess, filename, name = None, inp_tokenizer = None, out_tokenizer = None, config = None):\n",
    "        \n",
    "        self.sess = sess\n",
    "        \n",
    "        if filename is None:\n",
    "            self.initialize(name, inp_tokenizer, out_tokenizer, config)\n",
    "        else:\n",
    "            self.load(filename)\n",
    "    \n",
    "    \n",
    "    def initialize(self, name, inp_tokenizer, out_tokenizer, config):\n",
    "        \n",
    "        assert type(config) == AttentiveModel.Config\n",
    "        \n",
    "        self.name = name\n",
    "        self.inp_tokenizer = inp_tokenizer\n",
    "        self.out_tokenizer = out_tokenizer\n",
    "        self.inp_voc = inp_tokenizer._vocab\n",
    "        self.out_voc = out_tokenizer._vocab\n",
    "        self.config = config\n",
    "        cfg = config\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            # YOUR CODE - define model layers\n",
    "            \n",
    "            # <...>\n",
    "            self.emb_inp = L.Embedding(len(self.inp_voc), cfg.emb_size)\n",
    "            self.emb_out = L.Embedding(len(self.out_voc), cfg.emb_size)\n",
    "            self.enc_lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(cfg.hid_size)\n",
    "            self.enc_lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(cfg.hid_size)\n",
    "            #self.enc0 = tf.nn.rnn_cell.GRUCell(cfg.hid_size)\n",
    "\n",
    "            self.dec_start = L.Dense(cfg.hid_size)\n",
    "            self.dec0 = tf.nn.rnn_cell.GRUCell(cfg.hid_size)\n",
    "            self.dense = L.Dense(cfg.hid_size)\n",
    "            self.activ = tf.tanh\n",
    "            self.logits = L.Dense(len(self.out_voc))\n",
    "            \n",
    "            self.attention = AttentionLayer(name = 'attention',\n",
    "                                            hid_size = 2 * cfg.hid_size)\n",
    "            \n",
    "            self._ru_char_encoder = RuCharEncoder(name = 'ru_char_encoder',\n",
    "                                                  config = cfg.ru_char_encoder_config,\n",
    "                                                  is_training = True)\n",
    "            \n",
    "            self.meter_model = MeterModel(name = 'meter',\n",
    "                                          config = cfg.meter_config,\n",
    "                                          batch_size = cfg.batch_size,\n",
    "                                          is_training = True,\n",
    "                                          ru_char_encoder = self._ru_char_encoder)\n",
    "            \n",
    "            # END OF YOUR CODE\n",
    "            \n",
    "            # prepare to translate_lines\n",
    "            self.inp = tf.placeholder('int32', [None, None])\n",
    "            self.initial_state = self.prev_state = self.encode(self.inp)\n",
    "            self.prev_tokens = tf.placeholder('int32', [None])\n",
    "            self.prev_char_tokens = tf.placeholder('int32', [None, None])\n",
    "            self.next_state, self.next_logits = self.decode(self.prev_state, self.prev_tokens, self.prev_char_tokens)\n",
    "            self.next_softmax = tf.nn.softmax(self.next_logits)\n",
    "\n",
    "            self.trainable_variables = get_scope_trainable_variables()\n",
    "        \n",
    "        # Call to 'K.get_session()' runs variable initializes for\n",
    "        # all variables including ones initialized using\n",
    "        # 'tf.global_variables_initializer()' (at least for Keras\n",
    "        # 2.0.5) thus it have to be called once here or model weights\n",
    "        # will be rewritten after training e.g. when 'get_weights' is\n",
    "        # called.\n",
    "        K.get_session()\n",
    "    \n",
    "    def to_out_char_matrix(self, out_tok_matrix, max_tok_len = 10):\n",
    "        return self._ru_char_encoder.tok_matrix_to_char_matrix(self.out_voc, out_tok_matrix, max_tok_len)\n",
    "    \n",
    "    def to_meter_inp_char_matrix(self, inp_lines, max_matrix_width = 100):\n",
    "        return self._ru_char_encoder.lines_to_char_matrix(inp_lines, max_matrix_width)\n",
    "    \n",
    "    def to_meter_out_stress_matrix(self, stress_lines):\n",
    "        return self.meter_model.to_stress_matrix(stress_lines)\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Takes symbolic input sequence, computes initial state\n",
    "        :param inp: matrix of input tokens [batch, time]\n",
    "        :return: a list of initial decoder state tensors\n",
    "        \"\"\"\n",
    "        \n",
    "        # encode input sequence, create initial decoder states\n",
    "        # <YOUR CODE>\n",
    "        inp_lengths = infer_length(inp, self.inp_voc.eos_ix)\n",
    "        inp_mask = infer_mask(inp, self.inp_voc.eos_ix, dtype = tf.bool)\n",
    "        \n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        with tf.variable_scope('enc0'):\n",
    "            #enc_seq, enc_last = tf.nn.dynamic_rnn(self.enc0,\n",
    "            #                                      inp_emb,\n",
    "            #                                      sequence_length = inp_lengths,\n",
    "            #                                      dtype = inp_emb.dtype)\n",
    "            ((enc_seq_fw,\n",
    "              enc_seq_bw),\n",
    "             ((enc_last_fw_cell_state,\n",
    "               enc_last_fw_hid_state),\n",
    "              enc_last_bw_state_tuple)) = tf.nn.bidirectional_dynamic_rnn(self.enc_lstm_fw_cell,\n",
    "                                                                          self.enc_lstm_bw_cell,\n",
    "                                                                          inp_emb,\n",
    "                                                                          sequence_length = inp_lengths,\n",
    "                                                                          dtype = inp_emb.dtype)\n",
    "        enc_seq = tf.concat((enc_seq_fw, enc_seq_bw), axis = -1)\n",
    "        # TODO: Don't feed cell LSTM state to decoder\n",
    "        enc_last_fw = tf.concat([enc_last_fw_cell_state,\n",
    "                                 enc_last_fw_hid_state], axis = 1)\n",
    "        dec_start = self.dec_start(enc_last_fw)\n",
    "        \n",
    "        # apply attention layer from initial decoder hidden state\n",
    "        #first_attn_probas = <...>\n",
    "        _, first_attn_probas = self.attention(enc_seq, dec_start, inp_mask)\n",
    "        \n",
    "        # Build first state: include\n",
    "        # * initial states for decoder recurrent layers\n",
    "        # * encoder sequence and encoder attn mask (for attention)\n",
    "        # * make sure that last state item is attention probabilities tensor\n",
    "        \n",
    "        #first_state = [<...>, first_attn_probas]\n",
    "        first_state = [dec_start, enc_seq, inp_mask, first_attn_probas]\n",
    "        return first_state\n",
    "\n",
    "    def decode(self, prev_state, prev_tokens, prev_char_tokens):\n",
    "        \"\"\"\n",
    "        Takes previous decoder state and tokens, returns new state and logits\n",
    "        :param prev_state: a list of previous decoder state tensors\n",
    "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
    "        :param prev_char_tokens: previous output tokens, an int vector of [batch_size, max_tok_len_in_chars]\n",
    "        :return: a list of next decoder state tensors, a tensor of logits [batch,n_tokens]\n",
    "        \"\"\"\n",
    "        # Unpack your state: you will get tensors in the same order\n",
    "        # that you've packed in encode\n",
    "        #[<...>, prev_attn_probas] = prev_state\n",
    "        [prev_dec, enc_seq, inp_mask, prev_attn_probas] = prev_state\n",
    "        \n",
    "        \n",
    "        # Perform decoder step\n",
    "        # * predict next attn response and attn probas given previous decoder state\n",
    "        # * use prev token embedding and attn response to update decoder states\n",
    "        # * (concatenate and feed into decoder cell)\n",
    "        # * predict logits\n",
    "        \n",
    "        # <APPLY_ATTENTION>\n",
    "        next_attn_response, next_attn_probas = self.attention(enc_seq, prev_dec, inp_mask)\n",
    "\n",
    "        # <YOUR CODE>\n",
    "        prev_emb = self.emb_out(prev_tokens[:, tf.newaxis])[:,0]\n",
    "        \n",
    "        _, prev_char_hid = self._ru_char_encoder.encode(prev_char_tokens)\n",
    "        \n",
    "        dec_inputs = tf.concat([prev_emb, prev_char_hid, next_attn_response], axis = 1)\n",
    "        with tf.variable_scope('dec0'):\n",
    "            new_dec_out, new_dec_state = self.dec0(dec_inputs, prev_dec)\n",
    "        output_logits = self.logits(self.activ(self.dense(new_dec_out)))\n",
    "        #output_logits = self.logits(self.activ(new_dec_out))\n",
    "        \n",
    "        # Pack new state:\n",
    "        # * replace previous decoder state with next one\n",
    "        # * copy encoder sequence and mask from prev_state\n",
    "        # * append new attention probas\n",
    "        #next_state = [<...>, next_attn_probas]\n",
    "        next_state = [new_dec_state, enc_seq, inp_mask, next_attn_probas]\n",
    "        return next_state, output_logits\n",
    "\n",
    "    \n",
    "    def compute_logits(self, inp, out, out_char):\n",
    "        \n",
    "        batch_size = tf.shape(inp)[0]\n",
    "\n",
    "        # Encode inp, get initial state\n",
    "        first_state = self.encode(inp) # <YOUR CODE HERE>\n",
    "\n",
    "        # initial logits: always predict BOS\n",
    "        first_logits = tf.log(tf.one_hot(tf.fill([batch_size], self.out_voc.bos_ix),\n",
    "                                         len(self.out_voc)) + 1e-30)\n",
    "\n",
    "        # Decode step\n",
    "        def step(prev_state, y_prev, y_char_prev):\n",
    "            # Given previous state, obtain next state and next token logits\n",
    "            # <YOUR CODE>\n",
    "            next_dec_state, next_logits = self.decode(prev_state, y_prev, y_char_prev)\n",
    "            return next_dec_state, next_logits # <...>\n",
    "\n",
    "        # You can now use tf.scan to run step several times.\n",
    "        # use tf.transpose(out) as elems (to process one time-step at a time)\n",
    "        # docs: https://www.tensorflow.org/api_docs/python/tf/scan\n",
    "\n",
    "        # <YOUR CODE>\n",
    "\n",
    "        out = tf.scan(lambda a, y: step(a[0], y[0], y[1]),\n",
    "                      elems = (tf.transpose(out)[:-1], tf.transpose(out_char, [1, 0, 2])[:-1]),\n",
    "                      initializer = (first_state, first_logits))\n",
    "\n",
    "\n",
    "        # FIXME remove?\n",
    "        #self.sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        logits_seq = out[1] # <YOUR CODE>\n",
    "\n",
    "        # prepend first_logits to logits_seq\n",
    "        logits_seq = tf.concat((first_logits[tf.newaxis], logits_seq), axis = 0) #<...>\n",
    "\n",
    "        # Make sure you convert logits_seq from\n",
    "        # [time, batch, voc_size] to [batch, time, voc_size]\n",
    "        logits_seq = tf.transpose(logits_seq, perm = [1, 0, 2]) #<...>\n",
    "\n",
    "        return logits_seq\n",
    "\n",
    "    def compute_loss(self, inp, out, out_char):\n",
    "        \n",
    "        mask = infer_mask(out, self.out_voc.eos_ix)    \n",
    "        logits_seq = self.compute_logits(inp, out, out_char)\n",
    "\n",
    "        # Compute loss as per instructions above\n",
    "        # <YOUR CODE>\n",
    "\n",
    "        prob_seq = tf.nn.softmax(logits_seq)\n",
    "        out_one_hot = tf.one_hot(out, len(self.out_voc))\n",
    "\n",
    "        prob_seq_masked = tf.boolean_mask(prob_seq, mask)\n",
    "        out_one_hot_masked = tf.boolean_mask(out_one_hot, mask)\n",
    "        prob_seq_out = tf.boolean_mask(prob_seq_masked, out_one_hot_masked)\n",
    "        loss = tf.reduce_mean(-tf.log(prob_seq_out))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def make_initial_state(self, inp_lines):\n",
    "        return self.sess.run(self.initial_state,\n",
    "                             {self.inp: self.inp_tokenizer.lines_to_matrix(inp_lines,\n",
    "                                                                           max_matrix_width = None)})\n",
    "    \n",
    "    def get_next_state_and_logits(self, state, outputs):\n",
    "        \n",
    "        if type(outputs) == list:\n",
    "            prev_tokens = np.array([out[-1] for out in outputs], dtype = np.int32)\n",
    "        else:\n",
    "            prev_tokens = outputs[:, -1]\n",
    "        prev_char_tokens = np.squeeze(self.to_out_char_matrix(prev_tokens[:, np.newaxis]), axis = 1)\n",
    "        \n",
    "        return self.sess.run([self.next_state, self.next_logits],\n",
    "                             {**dict(zip(self.prev_state, state)),\n",
    "                              self.prev_tokens: prev_tokens,\n",
    "                              self.prev_char_tokens: prev_char_tokens})\n",
    "                         \n",
    "    def get_output_vocabulary(self):\n",
    "        return self.out_voc\n",
    "    \n",
    "    \n",
    "    def translate_lines(self, inp_lines, max_len=100):\n",
    "        \"\"\"\n",
    "        Translates a list of lines by greedily selecting most likely next token at each step\n",
    "        :returns: a list of output lines, a sequence of model states at each step\n",
    "        \"\"\"\n",
    "        state = self.make_initial_state(inp_lines)\n",
    "        outputs = [[self.out_voc.bos_ix] for _ in range(len(inp_lines))]\n",
    "        all_states = [state]\n",
    "        finished = [False] * len(inp_lines)\n",
    "\n",
    "        for t in range(max_len):\n",
    "            state, logits = self.get_next_state_and_logits(state, outputs)\n",
    "            next_tokens = np.argmax(logits, axis=-1)\n",
    "            all_states.append(state)\n",
    "            for i in range(len(next_tokens)):\n",
    "                outputs[i].append(next_tokens[i])\n",
    "                finished[i] |= next_tokens[i] == self.out_voc.eos_ix\n",
    "        return self.out_tokenizer.matrix_to_lines(np.array(outputs)), all_states\n",
    "    \n",
    "    def dump(self, filename):\n",
    "        \n",
    "        assert False, 'Not implemented yet'\n",
    "        values = {'name': self.name,\n",
    "                  'config': self.config.as_dict(),\n",
    "                  'inp_voc': self.inp_voc,\n",
    "                  'out_voc': self.out_voc,\n",
    "                  'emb_inp_weights': self.emb_inp.get_weights(),\n",
    "                  'emb_out_weights': self.emb_out.get_weights(),\n",
    "                  #'enc0_weights': self.enc0.get_weights(),\n",
    "                  'enc_lstm_fw_cell_weights': self.enc_lstm_fw_cell.get_weights(),\n",
    "                  'enc_lstm_bw_cell_weights': self.enc_lstm_bw_cell.get_weights(),\n",
    "                  'dec0_weights': self.dec0.get_weights(),\n",
    "                  'dec_start_weights': self.dec_start.get_weights(),\n",
    "                  'dense_weights': self.dense.get_weights(),\n",
    "                  'logits_weights': self.logits.get_weights(),\n",
    "                  'attn__linear_e_weights': self.attention.linear_e.get_weights(),\n",
    "                  'attn__linear_d_weights': self.attention.linear_d.get_weights(),\n",
    "                  'attn__linear_out_weights': self.attention.linear_out.get_weights()}\n",
    "        pickle.dump(values, open(filename, 'wb'))\n",
    "    \n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            values = pickle.load(f)\n",
    "        self.initialize(values['name'], values['inp_voc'], values['out_voc'],\n",
    "                        AttentiveModel.Config(**values['config']))\n",
    "        self.emb_inp.set_weights(values['emb_inp_weights'])\n",
    "        self.emb_out.set_weights(values['emb_out_weights'])\n",
    "        #self.enc0.set_weights(values['enc0_weights'])\n",
    "        self.enc_lstm_fw_cell.set_weights(values['enc_lstm_fw_cell_weights'])\n",
    "        self.enc_lstm_bw_cell.set_weights(values['enc_lstm_bw_cell_weights'])\n",
    "        self.dec0.set_weights(values['dec0_weights'])\n",
    "        self.dec_start.set_weights(values['dec_start_weights'])\n",
    "        self.dense.set_weights(values['dense_weights'])\n",
    "        self.logits.set_weights(values['logits_weights'])\n",
    "        self.attention.linear_e.set_weights(values['attn__linear_e_weights'])\n",
    "        self.attention.linear_d.set_weights(values['attn__linear_d_weights'])\n",
    "        self.attention.linear_out.set_weights(values['attn__linear_out_weights'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def compute_bleu(model, inp_lines, out_lines, **flags):\n",
    "    \"\"\" Estimates corpora-level BLEU score of model's translations\n",
    "        given inp and reference out \"\"\"\n",
    "    translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "    # Note: if you experience out-of-memory error,\n",
    "    # split input lines into batches and translate separately\n",
    "    return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n",
    "\n",
    "def compute_bleu_large(model, inp_lines, out_lines):\n",
    "    batch_size = 256\n",
    "    result = 0.0\n",
    "    for i in range(0, inp_lines.shape[0], batch_size):\n",
    "        current_bleu = compute_bleu(model,\n",
    "                                    inp_lines[i:i+batch_size],\n",
    "                                    out_lines[i:i+batch_size])\n",
    "        current_bleu *= min(i + batch_size, inp_lines.shape[0]) - i\n",
    "        result += current_bleu\n",
    "    result /= inp_lines.shape[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aaklepova/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1190: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/aaklepova/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1297: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/aaklepova/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model_config = AttentiveModel.Config(emb_size = 128,\n",
    "                                     hid_size = 256,\n",
    "                                     batch_size = 32,\n",
    "                                     ru_char_encoder_config = RuCharEncoder.deepspeare_en_config,\n",
    "                                     meter_config = MeterModel.deepspeare_config)\n",
    "model_name = 'translator_attn_reversed_amalgama_subtitles_with_pentameter_shakespeare_16_03_2019'\n",
    "\n",
    "if 'sess' in globals():\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "model = AttentiveModel(sess,\n",
    "                       filename = None,\n",
    "                       name = model_name,\n",
    "                       inp_tokenizer = en_tokenizer,\n",
    "                       out_tokenizer = ru_tokenizer,\n",
    "                       config = model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaklepova/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f341795dc88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator_inp = tf.placeholder('int32', [None, None])\n",
    "translator_out = tf.placeholder('int32', [None, None])\n",
    "translator_out_char = tf.placeholder('int32', [None, None, None])\n",
    "\n",
    "meter_inp = model.meter_model.get_input()\n",
    "meter_out = model.meter_model.get_output()\n",
    "\n",
    "translator_loss = model.compute_loss(translator_inp, translator_out, translator_out_char)\n",
    "translator_train_step = tf.train.AdamOptimizer().minimize(translator_loss)\n",
    "meter_loss = model.meter_model.pm_mean_cost\n",
    "meter_train_step = model.meter_model.pm_train_op\n",
    "K.get_session() # To not reset optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_last_file_test_time = 0\n",
    "\n",
    "def should_stop_train():\n",
    "    t = monotonic()\n",
    "    if t - _last_file_test_time > 2: # seconds\n",
    "        return os.path.exists('stop-train')\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_history(metrics):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    for i, (name, history) in enumerate(sorted(metrics.items())):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        plt.title(name)\n",
    "        plt.plot(*zip(*history))\n",
    "        plt.grid()\n",
    "    plt.show()\n",
    "    print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0)[1],\n",
    "          flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "metrics = {'train_loss': [], 'dev_bleu': [], 'meter_train_loss': []}\n",
    "sess.run(tf.global_variables_initializer())\n",
    "batch_size = model_config.batch_size\n",
    "dev_batch_size = 128\n",
    "    \n",
    "train_batches = dataset.iterate_train_minibatches(max_batch_matrix_width = None,\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  epoch_count = None) # Never stop\n",
    "\n",
    "\n",
    "\n",
    "def train_translator_and_pentameter(dataset,\n",
    "                                    dev_src_lines,\n",
    "                                    dev_tgt_lines,\n",
    "                                    iters):\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    en_tokenizer = dataset.get_tokenizer(Lang.EN)\n",
    "    ru_tokenizer = dataset.get_tokenizer(Lang.RU)\n",
    "\n",
    "    for _ in trange(iters):\n",
    "    #for _ in range(iters):\n",
    "        step = len(metrics['train_loss']) + 1\n",
    "        \n",
    "        train_translator = True\n",
    "        train_meter = True\n",
    "        \n",
    "        meter_batch = train_meter and step % 100 == 0\n",
    "        \n",
    "        if meter_batch:\n",
    "            meter_batch_ix = set(list(np.random.choice(len(train_sonnet_lines_russian),\n",
    "                                                       size = batch_size,\n",
    "                                                       replace = False)))\n",
    "            \n",
    "            meter_en_lines = [x for i, x in enumerate(train_sonnet_lines_english)\n",
    "                               if i in meter_batch_ix]\n",
    "            meter_ru_lines = [x for i, x in enumerate(train_sonnet_lines_russian)\n",
    "                               if i in meter_batch_ix]\n",
    "            meter_ru_stresses = [x for i, x in enumerate(train_sonnet_lines_russian_stresses)\n",
    "                                  if i in meter_batch_ix]\n",
    "            \n",
    "            assert len(meter_en_lines) == len(meter_ru_lines) == len(meter_ru_stresses) == batch_size\n",
    "        \n",
    "        if train_translator:\n",
    "            \n",
    "            if meter_batch:\n",
    "                train_batch_src_matrix = en_tokenizer.lines_to_matrix(meter_en_lines, max_matrix_width = None)\n",
    "                train_batch_tgt_matrix = ru_tokenizer.lines_to_matrix(meter_ru_lines, max_matrix_width = None)\n",
    "            else:\n",
    "                train_batch_src_matrix, train_batch_tgt_matrix = next(train_batches)\n",
    "            \n",
    "            translator_tgt_char_matrix = model.to_out_char_matrix(train_batch_tgt_matrix)\n",
    "            \n",
    "            translator_feed_dict = {\n",
    "                translator_inp: train_batch_src_matrix,\n",
    "                translator_out: train_batch_tgt_matrix,\n",
    "                translator_out_char: translator_tgt_char_matrix,\n",
    "            }\n",
    "\n",
    "            translator_loss_t, _ = sess.run([translator_loss, translator_train_step],\n",
    "                                            translator_feed_dict)\n",
    "            metrics['train_loss'].append((step, translator_loss_t))\n",
    "        \n",
    "        if meter_batch:\n",
    "\n",
    "            meter_feed_dict = {\n",
    "                meter_inp: model.to_meter_inp_char_matrix(meter_ru_lines),\n",
    "                meter_out: model.to_meter_out_stress_matrix(meter_ru_stresses)\n",
    "            }\n",
    "\n",
    "            meter_loss_t, _ = sess.run([meter_loss, meter_train_step],\n",
    "                                       meter_feed_dict)\n",
    "            metrics['meter_train_loss'].append((step, meter_loss_t))\n",
    "        \n",
    "        \n",
    "\n",
    "        if step % 100 == 0:\n",
    "            batch_dev_ix = np.random.randint(len(dev_src_lines), size=dev_batch_size)\n",
    "            metrics['dev_bleu'].append((step, compute_bleu(model,\n",
    "                                                           [dev_src_lines[i] for i in batch_dev_ix],\n",
    "                                                           [dev_tgt_lines[i] for i in batch_dev_ix])))\n",
    "\n",
    "            clear_output(True)\n",
    "            show_history(metrics)\n",
    "        #if step % 10000 == 0:\n",
    "        #    model.dump('{}.pkl'.format(model.name))\n",
    "        if should_stop_train():\n",
    "            print('Stopping train.')\n",
    "            break\n",
    "            \n",
    "    end = datetime.datetime.now()\n",
    "    print('Execution time: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss=2.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 151147/200000 [15:22:31<4:27:26,  3.04it/s] "
     ]
    }
   ],
   "source": [
    "train_translator_and_pentameter(\n",
    "    dataset,\n",
    "    dev_src_lines,\n",
    "    dev_tgt_lines,\n",
    "    200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show_history(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
