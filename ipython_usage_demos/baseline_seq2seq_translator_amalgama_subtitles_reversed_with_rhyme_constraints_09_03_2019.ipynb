{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For BPE training, Vocab, etc. it requires ~ 70GB of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "amalgama_fname = \\\n",
    "'/srv/hd6/data/Poem2Poem/data/ParallelEnRu/Amalgama/amalgama-reversed-song-translations.jsonl'\n",
    "subtitles_fname = \\\n",
    "'/srv/hd6/data/Poem2Poem/data/ParallelEnRu/OpenSubtitlesv2018/en-ru-reversed.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(songs) 87208\n",
      "errors 0\n",
      "len(train_songs) 78487\n",
      "len(dev_songs) 8721\n",
      "[[[\"laer eb t'nac taht maerd a was I\", ',йодварп ьтыб тежом ен йыроток ,нос ледив Я'], ['dnim ym ot em sekat tI', ',еинанзосдоп еом в янем келву нО'], ['enim fo maerd live siht edisni kool woN', '.нос йынчарм йом тотэ в инялгаз ьрепеТ'], ['niar eht ni gniyd uoy tfel I', ',меджод доп ьтариму ябет ливатсо Я'], ['niap gnikcuf ym leef uoy woN', '!ьлоб юутялкорп юом еж йувтсвучоП'], ['enasni ma I wonk uoY', ',немузеб я отч ,ьшеанз ыТ'], [\"emas eht lla s'ti dne eht ni tuB\", '?еинечанз тееми отэ еокак ,воцнок ецнок в оН'], ['laer ylno ma I maerd siht nI', ',я окьлот нелаер енс мотэ В'], ['thginot niaga em htiw ylf dna dnah ym ekaT', 'юьчон йотэ мителу авонс йавад и ,укур юом имьзоВ'], ['thgilnoom gninihs eht ni yawa raF', ',адюсто ьладв меиняис мыннул доП'], ['eid lliw ew rehtegot dna reverof era eW', '.мерму ым етсемв и адгесван етсемв ыМ'], ['enog dna daed era uoy woN', ',тен ябет ,автрем ыт сачйеС'], [\"uoy rof erom on yrc t'now I\", ',ябет ьтавикалпо удуб ен ешьлоб Я'], [\"no gniog m'I yhw wonk t'nod I\", ',ьталед отэ юажлодорп я умечоп ,юанз еН'], ['uoy rof kcab gninrut ma I woN', '.ябет то ьсюавичаровто я ьрепеТ'], [\"eurt os lla s'ti ,daed era uoY\", ',умещяотсан-оп отэ есв ,автрем ыТ'], ['laer saw maerd siht lla retfA', ',видварп лыб нос тотэ икат-есВ'], [\"leef I niap ylno s'ti woN\", '.ьлоб ьшил юувтсвуч я сачйеС'], ['laer ylno ma I maerd siht nI', ',я окьлот нелаер енс мотэ В'], ['thginot niaga em htiw ylf dna dnah ym ekaT', 'юьчон йотэ мителу авонс йавад и ,укур юом имьзоВ'], ['thgilnoom gninihs eht ni yawa raF', ',адюсто ьладв меиняис мыннул доП'], ['eid lliw ew rehtegot dna reverof era eW', '.мерму ым етсемв и адгесван етсемв ыМ'], ['!og em teL', '!янем итсуптО']]]\n",
      "CPU times: user 35.2 s, sys: 1.69 s, total: 36.9 s\n",
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_amalgama_songs(dataset_fname):\n",
    "    songs = []\n",
    "    errors = 0\n",
    "    with codecs.open(dataset_fname,\n",
    "                     mode = 'r',\n",
    "                     encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == '':\n",
    "                continue\n",
    "            try:\n",
    "                song = json.loads(line)\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                print(e, '\\n', line)\n",
    "            songs.append([[line['texts'] \\\n",
    "                           for line in translation['lines'] \\\n",
    "                           if 'is_sub_caption' not in line \\\n",
    "                              and line['texts'] is not None] \\\n",
    "                          for translation in song['translations']])\n",
    "    return songs, errors\n",
    "    \n",
    "songs, errors = get_amalgama_songs(amalgama_fname)\n",
    "train_songs, dev_songs = train_test_split(songs, test_size = 0.1, random_state = 1)\n",
    "print('len(songs)', len(songs))\n",
    "print('errors', errors)\n",
    "print('len(train_songs)', len(train_songs))\n",
    "print('len(dev_songs)', len(dev_songs))\n",
    "print(train_songs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 0 ns, total: 11 µs\n",
      "Wall time: 25 µs\n",
      "len(amalgama_train_lines_foreign) 3287157\n",
      "len(amalgama_train_lines_russian) 3287157\n",
      "len(amalgama_dev_lines_foreign) 365556\n",
      "len(amalgama_dev_lines_russian) 365556\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "def get_lines_from_amalgama_songs(songs):\n",
    "    lines_foreign = []\n",
    "    lines_russian = []\n",
    "    for song in songs:\n",
    "        for translation in song:\n",
    "            for line_pair in translation:\n",
    "                if line_pair[0] is None or line_pair[1] is None:\n",
    "                    continue\n",
    "                lines_foreign.append(line_pair[0])\n",
    "                lines_russian.append(line_pair[1])\n",
    "    return lines_foreign, lines_russian\n",
    "\n",
    "(amalgama_train_lines_foreign,\n",
    " amalgama_train_lines_russian) = get_lines_from_amalgama_songs(train_songs)\n",
    "print('len(amalgama_train_lines_foreign)', len(amalgama_train_lines_foreign))\n",
    "print('len(amalgama_train_lines_russian)', len(amalgama_train_lines_russian))\n",
    "(amalgama_dev_lines_foreign,\n",
    " amalgama_dev_lines_russian) = get_lines_from_amalgama_songs(dev_songs)\n",
    "print('len(amalgama_dev_lines_foreign)', len(amalgama_dev_lines_foreign))\n",
    "print('len(amalgama_dev_lines_russian)', len(amalgama_dev_lines_russian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_subtitles) 19101477\n",
      "len(dev_subtitles) 2122387\n",
      "train_subtitles[3] [\".wols oot er'uoy ,amam no emoC\", 'еертсыб ,амаМ']\n",
      "dev_subtitles[3] ['.ylkciuq ,no emoC', '.еероксоп ,ман к идИ !оМ']\n",
      "CPU times: user 3min, sys: 11.1 s, total: 3min 11s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_subtitles(dataset_fname):\n",
    "    subtitles = []\n",
    "    with open(dataset_fname, mode = 'r', encoding = 'utf-8', newline = '') as f:\n",
    "        for line in f:\n",
    "            subtitles.append(json.loads(line.strip()))\n",
    "    return subtitles\n",
    "\n",
    "subtitles = get_subtitles(subtitles_fname)\n",
    "train_subtitles, dev_subtitles = train_test_split(subtitles,\n",
    "                                                  test_size = 0.1,\n",
    "                                                  random_state = 1)\n",
    "print('len(train_subtitles)', len(train_subtitles))\n",
    "print('len(dev_subtitles)', len(dev_subtitles))\n",
    "print('train_subtitles[3]', train_subtitles[3])\n",
    "print('dev_subtitles[3]', dev_subtitles[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(subtitles_train_lines_foreign) 19101477\n",
      "len(subtitles_train_lines_russian) 19101477\n",
      "len(subtitles_dev_lines_foreign) 2122387\n",
      "len(subtitles_dev_lines_russian) 2122387\n"
     ]
    }
   ],
   "source": [
    "def get_lines_from_subtitles(subtitles):\n",
    "    lines_foreign = []\n",
    "    lines_russian = []\n",
    "    for s in subtitles:\n",
    "        lines_foreign.append(s[0])\n",
    "        lines_russian.append(s[1])\n",
    "    return lines_foreign, lines_russian\n",
    "\n",
    "(subtitles_train_lines_foreign,\n",
    " subtitles_train_lines_russian) = get_lines_from_subtitles(train_subtitles)\n",
    "print('len(subtitles_train_lines_foreign)', len(subtitles_train_lines_foreign))\n",
    "print('len(subtitles_train_lines_russian)', len(subtitles_train_lines_russian))\n",
    "\n",
    "(subtitles_dev_lines_foreign,\n",
    " subtitles_dev_lines_russian) = get_lines_from_subtitles(dev_subtitles)\n",
    "print('len(subtitles_dev_lines_foreign)', len(subtitles_dev_lines_foreign))\n",
    "print('len(subtitles_dev_lines_russian)', len(subtitles_dev_lines_russian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_lines_foreign) 22388634\n",
      "len(train_lines_russian) 22388634\n"
     ]
    }
   ],
   "source": [
    "train_lines_foreign = amalgama_train_lines_foreign + subtitles_train_lines_foreign\n",
    "train_lines_russian = amalgama_train_lines_russian + subtitles_train_lines_russian\n",
    "print('len(train_lines_foreign)', len(train_lines_foreign))\n",
    "print('len(train_lines_russian)', len(train_lines_russian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 4s, sys: 37.7 s, total: 23min 42s\n",
      "Wall time: 23min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "tokenizer = WordPunctTokenizer()\n",
    "def tokenize(x):\n",
    "    return ' '.join(tokenizer.tokenize(x.lower()))\n",
    "\n",
    "\n",
    "bpe_dir_name = os.path.join( \\\n",
    "'/srv/hd7/data/aklyopova',\n",
    "'baseline_seq2seq_translator_amalgama_subtitles_reversed_with_rhyme_constraints_09_03_2019')\n",
    "\n",
    "def def_get_BPE_dicts(train_lines_foreign, train_lines_russian):\n",
    "\n",
    "    \n",
    "    with codecs.open(os.path.join(bpe_dir_name, 'train_lines_foreign'),\n",
    "                     mode = 'w',\n",
    "                     encoding = 'utf-8') as f:\n",
    "        f.write('\\n'.join(map(tokenize, train_lines_foreign)))\n",
    "    with codecs.open(os.path.join(bpe_dir_name, 'train_lines_russian'),\n",
    "                     mode = 'w',\n",
    "                     encoding = 'utf-8') as f:\n",
    "        f.write('\\n'.join(map(tokenize, train_lines_russian)))\n",
    "\n",
    "    bpe = {}\n",
    "    for lang in ['foreign', 'russian']:\n",
    "        learn_bpe(codecs.open(os.path.join(bpe_dir_name,\n",
    "                                           'train_lines_{}'.format(lang)),\n",
    "                              mode = 'r',\n",
    "                              encoding = 'utf-8'),\n",
    "                  codecs.open(os.path.join(bpe_dir_name,\n",
    "                                           'bpe_rules_{}_40000'.format(lang)),\n",
    "                              mode = 'w',\n",
    "                              encoding = 'utf-8'),\n",
    "                  num_symbols = 40000)\n",
    "        bpe[lang] = BPE(codecs.open(os.path.join(bpe_dir_name,\n",
    "                                                 'bpe_rules_{}_40000'.format(lang)),\n",
    "                                    mode = 'r',\n",
    "                                    encoding = 'utf-8'))\n",
    "    return bpe\n",
    "\n",
    "bpe = def_get_BPE_dicts(train_lines_foreign, train_lines_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 7s, sys: 38.1 s, total: 21min 45s\n",
      "Wall time: 21min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "amalgama_train_lines_foreign_bpe = \\\n",
    "[bpe['foreign'].process_line(line.strip()) for line in amalgama_train_lines_foreign]\n",
    "amalgama_dev_lines_foreign_bpe = \\\n",
    "[bpe['foreign'].process_line(line.strip()) for line in amalgama_dev_lines_foreign]\n",
    "subtitles_train_lines_foreign_bpe = \\\n",
    "[bpe['foreign'].process_line(line.strip()) for line in subtitles_train_lines_foreign]\n",
    "subtitles_dev_lines_foreign_bpe = \\\n",
    "[bpe['foreign'].process_line(line.strip()) for line in subtitles_dev_lines_foreign]\n",
    "\n",
    "amalgama_train_lines_russian_bpe = \\\n",
    "[bpe['russian'].process_line(line.strip()) for line in amalgama_train_lines_russian]\n",
    "amalgama_dev_lines_russian_bpe = \\\n",
    "[bpe['russian'].process_line(line.strip()) for line in amalgama_dev_lines_russian]\n",
    "subtitles_train_lines_russian_bpe = \\\n",
    "[bpe['russian'].process_line(line.strip()) for line in subtitles_train_lines_russian]\n",
    "subtitles_dev_lines_russian_bpe = \\\n",
    "[bpe['russian'].process_line(line.strip()) for line in subtitles_dev_lines_russian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(amalgama_train_lines_foreign_bpe))\n",
    "print(type(subtitles_train_lines_foreign_bpe))\n",
    "print(type(amalgama_train_lines_foreign_bpe[0]))\n",
    "print(type(subtitles_train_lines_foreign_bpe[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 12.1 s, total: 33.7 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_inp = np.array([line[:150] for line in amalgama_train_lines_foreign_bpe] + \\\n",
    "                     [line[:150] for line in subtitles_train_lines_foreign_bpe])\n",
    "train_out = np.array([line[:150] for line in amalgama_train_lines_russian_bpe] + \\\n",
    "                     [line[:150] for line in subtitles_train_lines_russian_bpe])\n",
    "\n",
    "dev_inp = np.array([line[:150] for line in amalgama_dev_lines_foreign_bpe] + \\\n",
    "                   [line[:150] for line in subtitles_dev_lines_foreign_bpe])\n",
    "dev_out = np.array([line[:150] for line in amalgama_dev_lines_russian_bpe] + \\\n",
    "                   [line[:150] for line in subtitles_dev_lines_russian_bpe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "amalgama_train_inp = np.array([line[:150] for line in amalgama_train_lines_foreign_bpe])\n",
    "amalgama_train_out = np.array([line[:150] for line in amalgama_train_lines_russian_bpe])\n",
    "\n",
    "amalgama_dev_inp = np.array([line[:150] for line in amalgama_dev_lines_foreign_bpe])\n",
    "amalgama_dev_out = np.array([line[:150] for line in amalgama_dev_lines_russian_bpe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "['yats ot yenom fo tuo nar uoy nehw devom uo@@ Y'\n",
      " \"oi@@ h@@ O ni esuoh '@@ stnerap ruo@@ Y\"\n",
      " 'won ,@@ llimdaert a htiw decalper deb dlo ruo@@ Y'\n",
      " 'wonk uoy naht erom ereh emoc I lle@@ W'\n",
      " \"uoy nworgtuo ev@@ '@@ I kniht uoy erus m@@ '@@ I dn@@ A\"]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "words to ids (0 = bos, 1 = eos):\n",
      "[[    0 45341 28168 45859 14228 44039 23667 44380 24061  6485 44345   655\n",
      "      1     1     1]\n",
      " [    0 27612 17357   625 24594 12520    55 39396 32358   655     1     1\n",
      "      1     1     1]\n",
      " [    0 44925    98 21631   689 18418  3685  3634  6900 32358   655     1\n",
      "      1     1     1]\n",
      " [    0 44928 44380 23319 11847 11652 10805   607 21500   649     1     1\n",
      "      1     1     1]\n",
      " [    0 44380 27189 13424    55   607 19753 44380 11980 22161    55   607\n",
      "   6974   583     1]]\n",
      "\n",
      "back to words\n",
      "['yats ot yenom fo tuo nar uoy nehw devom uo@@ Y', \"oi@@ h@@ O ni esuoh '@@ stnerap ruo@@ Y\", 'won ,@@ llimdaert a htiw decalper deb dlo ruo@@ Y', 'wonk uoy naht erom ereh emoc I lle@@ W', \"uoy nworgtuo ev@@ '@@ I kniht uoy erus m@@ '@@ I dn@@ A\"]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# utils.py is copied from Homework 4 assignment as is\n",
    "from utils import Vocab\n",
    "inp_voc = Vocab.from_lines(train_inp)\n",
    "out_voc = Vocab.from_lines(train_out)\n",
    "# Here's how you cast lines into ids and backwards.\n",
    "batch_lines = dev_inp[5:10]\n",
    "batch_ids = inp_voc.to_matrix(batch_lines)\n",
    "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
    "\n",
    "print(\"lines\")\n",
    "print(batch_lines)\n",
    "print(type(batch_lines))\n",
    "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
    "print(batch_ids)\n",
    "print(\"\\nback to words\")\n",
    "print(batch_lines_restored)\n",
    "print(type(batch_lines_restored))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.340170e+05, 5.671517e+06, 8.525846e+06, 3.452584e+06,\n",
       "        2.287987e+06, 8.482770e+05, 6.122800e+05, 3.039580e+05,\n",
       "        2.753690e+05, 5.920100e+04, 1.400000e+04, 2.898000e+03,\n",
       "        6.900000e+02, 7.000000e+00, 0.000000e+00, 2.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 1.000000e+00]),\n",
       " array([ 0. ,  3.5,  7. , 10.5, 14. , 17.5, 21. , 24.5, 28. , 31.5, 35. ,\n",
       "        38.5, 42. , 45.5, 49. , 52.5, 56. , 59.5, 63. , 66.5, 70. ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(map(len, map(str.split, train_inp))), bins=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(map(len, map(str.split, train_out))), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "import tensorflow as tf\n",
    "import keras.layers as L\n",
    "from keras import backend as K\n",
    "from utils import infer_length, infer_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils import select_values_over_last_axis\n",
    "import rupo.api\n",
    "\n",
    "class AttentionLayer:\n",
    "    def __init__(self, name, hid_size, activ=tf.tanh,):\n",
    "        \"\"\" A layer that computes additive attention response and weights \"\"\"\n",
    "        self.name = name\n",
    "        self.hid_size = hid_size # attention layer hidden units\n",
    "        self.activ = activ       # attention layer hidden nonlinearity\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            # YOUR CODE - create layer variables\n",
    "            #<YOUR CODE>\n",
    "            self.linear_e = L.Dense(hid_size)\n",
    "            self.linear_d = L.Dense(hid_size)\n",
    "            self.linear_out = L.Dense(1)\n",
    "\n",
    "    def __call__(self, enc, dec, inp_mask):\n",
    "        \"\"\"\n",
    "        Computes attention response and weights\n",
    "        :param enc: encoder activation sequence, float32[batch_size, ninp, enc_size]\n",
    "        :param dec: single decoder state used as \"query\", float32[batch_size, dec_size]\n",
    "        :param inp_mask: mask on enc activatons (0 after first eos), float32 [batch_size, ninp]\n",
    "        :returns: attn[batch_size, enc_size], probs[batch_size, ninp]\n",
    "            - attn - attention response vector (weighted sum of enc)\n",
    "            - probs - attention weights after softmax\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(self.name):\n",
    "            \n",
    "            # Compute logits\n",
    "            #<...>\n",
    "            logits_seq = self.linear_out(self.activ(self.linear_e(enc) + \\\n",
    "                                                    self.linear_d(dec)[:, tf.newaxis, :]))\n",
    "            logits_seq = tf.squeeze(logits_seq, axis = -1)\n",
    "            \n",
    "            # Apply mask - if mask is 0, logits should be -inf or -1e9\n",
    "            # You may need tf.where\n",
    "            #<...>\n",
    "            \n",
    "            logits_seq = tf.where(inp_mask, logits_seq, tf.fill(tf.shape(logits_seq),\n",
    "                                                                -np.inf))\n",
    "            \n",
    "            # Compute attention probabilities (softmax)\n",
    "            probs = tf.nn.softmax(logits_seq) # <...>\n",
    "            \n",
    "            # Compute attention response using enc and probs\n",
    "            attn = tf.reduce_sum(probs[..., tf.newaxis] * enc, axis = 1) # <...>\n",
    "            \n",
    "            return attn, probs\n",
    "        \n",
    "RHYME_PREFIX = 1\n",
    "RHYME_WORD = 2\n",
    "        \n",
    "class AttentiveModel:\n",
    "    def __init__(self, filename, name = None, inp_voc = None, out_voc = None,\n",
    "                 emb_size = None, hid_size = None):\n",
    "        \n",
    "        self.vowels = {'а','е','ё','и','о','у','ы','э','ю','я'}\n",
    "        self.consonants = {'б','в','г','д','ж','з','к','л','м',\n",
    "                           'н','п','р','с','т','ф','х','ц','ч','ш','щ','ъ','ь'}\n",
    "        \n",
    "        self.rupo_engine = rupo.api.Engine(language = 'ru')\n",
    "        rupo_data_root = '/srv/hd6/data/Poem2Poem/data/rupo/'\n",
    "        self.rupo_engine.load(rupo_data_root + \\\n",
    "                              'stress_models/stress_ru_LSTM64_dropout0.2_acc99_wer8.h5',\n",
    "                              rupo_data_root + 'dict/zaliznyak.txt')\n",
    "        \n",
    "        if filename is None:\n",
    "            self.initialize(name, inp_voc, out_voc,\n",
    "                            emb_size, hid_size) #, attn_size)\n",
    "        else:\n",
    "            self.load(filename)\n",
    "    \n",
    "    \n",
    "    def initialize(self, name, inp_voc, out_voc,\n",
    "                   emb_size, hid_size): #, attn_size):\n",
    "        \n",
    "        self.name = name\n",
    "        self.inp_voc = inp_voc\n",
    "        self.out_voc = out_voc\n",
    "        self.emb_size = emb_size\n",
    "        self.hid_size = hid_size\n",
    "        #self.attn_size = attn_size\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            # YOUR CODE - define model layers\n",
    "            \n",
    "            # <...>\n",
    "            self.emb_inp = L.Embedding(len(inp_voc), emb_size)\n",
    "            self.emb_out = L.Embedding(len(out_voc), emb_size)\n",
    "            self.enc_lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(hid_size,\n",
    "                                                                 forget_bias=1.0,\n",
    "                                                                 state_is_tuple = False)\n",
    "            self.enc_lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(hid_size,\n",
    "                                                                 forget_bias=1.0,\n",
    "                                                                 state_is_tuple = False)\n",
    "            #self.enc0 = tf.nn.rnn_cell.GRUCell(hid_size)\n",
    "\n",
    "            self.dec_start = L.Dense(hid_size)\n",
    "            self.dec0 = tf.nn.rnn_cell.GRUCell(hid_size)\n",
    "            self.dense = L.Dense(hid_size)\n",
    "            self.activ = tf.tanh\n",
    "            self.logits = L.Dense(len(out_voc))\n",
    "            \n",
    "            self.attention = AttentionLayer(name = 'attention',\n",
    "                                            #enc_size = None, # FIXME: Unused\n",
    "                                            #dec_size = None, # FIXME: Unused\n",
    "                                            #hid_size = attn_size)\n",
    "                                            hid_size = 2 * self.hid_size)\n",
    "            \n",
    "            # END OF YOUR CODE\n",
    "            \n",
    "            # prepare to translate_lines\n",
    "            self.inp = tf.placeholder('int32', [None, None])\n",
    "            self.initial_state = self.prev_state = self.encode(self.inp)\n",
    "            self.prev_tokens = tf.placeholder('int32', [None])\n",
    "            self.next_state, self.next_logits = self.decode(self.prev_state, self.prev_tokens)\n",
    "            self.next_softmax = tf.nn.softmax(self.next_logits)\n",
    "\n",
    "        self.weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=name)\n",
    "        \n",
    "        # Call to 'K.get_session()' runs variable initializes for\n",
    "        # all variables including ones initialized using\n",
    "        # 'tf.global_variables_initializer()' (at least for Keras\n",
    "        # 2.0.5) thus it have to be called once here or model weights\n",
    "        # will be rewritten after training e.g. when 'get_weights' is\n",
    "        # called.\n",
    "        K.get_session()\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Takes symbolic input sequence, computes initial state\n",
    "        :param inp: matrix of input tokens [batch, time]\n",
    "        :return: a list of initial decoder state tensors\n",
    "        \"\"\"\n",
    "        \n",
    "        # encode input sequence, create initial decoder states\n",
    "        # <YOUR CODE>\n",
    "        inp_lengths = infer_length(inp, self.inp_voc.eos_ix)\n",
    "        inp_mask = infer_mask(inp, self.inp_voc.eos_ix, dtype = tf.bool)\n",
    "        \n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        with tf.variable_scope('enc0'):\n",
    "            #enc_seq, enc_last = tf.nn.dynamic_rnn(self.enc0,\n",
    "            #                                      inp_emb,\n",
    "            #                                      sequence_length = inp_lengths,\n",
    "            #                                      dtype = inp_emb.dtype)\n",
    "            ((enc_seq_fw,\n",
    "              enc_seq_bw),\n",
    "             (enc_last_fw,\n",
    "              enc_last_bw)) = tf.nn.bidirectional_dynamic_rnn(self.enc_lstm_fw_cell,\n",
    "                                                              self.enc_lstm_bw_cell,\n",
    "                                                              inp_emb,\n",
    "                                                              sequence_length = inp_lengths,\n",
    "                                                              dtype = inp_emb.dtype)\n",
    "        enc_seq = tf.concat((enc_seq_fw, enc_seq_bw), axis = -1)\n",
    "        dec_start = self.dec_start(enc_last_fw)\n",
    "        \n",
    "        # apply attention layer from initial decoder hidden state\n",
    "        #first_attn_probas = <...>\n",
    "        _, first_attn_probas = self.attention(enc_seq, dec_start, inp_mask)\n",
    "        \n",
    "        # Build first state: include\n",
    "        # * initial states for decoder recurrent layers\n",
    "        # * encoder sequence and encoder attn mask (for attention)\n",
    "        # * make sure that last state item is attention probabilities tensor\n",
    "        \n",
    "        #first_state = [<...>, first_attn_probas]\n",
    "        first_state = [dec_start, enc_seq, inp_mask, first_attn_probas]\n",
    "        return first_state\n",
    "\n",
    "    def decode(self, prev_state, prev_tokens, **flags):\n",
    "        \"\"\"\n",
    "        Takes previous decoder state and tokens, returns new state and logits\n",
    "        :param prev_state: a list of previous decoder state tensors\n",
    "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
    "        :return: a list of next decoder state tensors, a tensor of logits [batch,n_tokens]\n",
    "        \"\"\"\n",
    "        # Unpack your state: you will get tensors in the same order\n",
    "        # that you've packed in encode\n",
    "        #[<...>, prev_attn_probas] = prev_state\n",
    "        [prev_dec, enc_seq, inp_mask, prev_attn_probas] = prev_state\n",
    "        \n",
    "        \n",
    "        # Perform decoder step\n",
    "        # * predict next attn response and attn probas given previous decoder state\n",
    "        # * use prev token embedding and attn response to update decoder states\n",
    "        # * (concatenate and feed into decoder cell)\n",
    "        # * predict logits\n",
    "        \n",
    "        # <APPLY_ATTENTION>\n",
    "        next_attn_response, next_attn_probas = self.attention(enc_seq, prev_dec, inp_mask)\n",
    "\n",
    "        # <YOUR CODE>\n",
    "        prev_emb = self.emb_out(prev_tokens[:,None])[:,0]\n",
    "        dec_inputs = tf.concat([prev_emb, next_attn_response], axis = 1)\n",
    "        with tf.variable_scope('dec0'):\n",
    "            new_dec_out, new_dec_state = self.dec0(dec_inputs, prev_dec)\n",
    "        output_logits = self.logits(self.activ(self.dense(new_dec_out)))\n",
    "        #output_logits = self.logits(self.activ(new_dec_out))\n",
    "        \n",
    "        # Pack new state:\n",
    "        # * replace previous decoder state with next one\n",
    "        # * copy encoder sequence and mask from prev_state\n",
    "        # * append new attention probas\n",
    "        #next_state = [<...>, next_attn_probas]\n",
    "        next_state = [new_dec_state, enc_seq, inp_mask, next_attn_probas]\n",
    "        return next_state, output_logits\n",
    "\n",
    "    \n",
    "    def compute_logits(self, inp, out, **flags):\n",
    "        \n",
    "        batch_size = tf.shape(inp)[0]\n",
    "\n",
    "        # Encode inp, get initial state\n",
    "        first_state = self.encode(inp) # <YOUR CODE HERE>\n",
    "\n",
    "        # initial logits: always predict BOS\n",
    "        first_logits = tf.log(tf.one_hot(tf.fill([batch_size], self.out_voc.bos_ix),\n",
    "                                         len(self.out_voc)) + 1e-30)\n",
    "\n",
    "        # Decode step\n",
    "        def step(prev_state, y_prev):\n",
    "            # Given previous state, obtain next state and next token logits\n",
    "            # <YOUR CODE>\n",
    "            next_dec_state, next_logits = self.decode(prev_state, y_prev)\n",
    "            return next_dec_state, next_logits # <...>\n",
    "\n",
    "        # You can now use tf.scan to run step several times.\n",
    "        # use tf.transpose(out) as elems (to process one time-step at a time)\n",
    "        # docs: https://www.tensorflow.org/api_docs/python/tf/scan\n",
    "\n",
    "        # <YOUR CODE>\n",
    "\n",
    "        out = tf.scan(lambda a, y: step(a[0], y),\n",
    "                      elems = tf.transpose(out)[:-1],\n",
    "                      initializer = (first_state, first_logits))\n",
    "\n",
    "\n",
    "        # FIXME remove?\n",
    "        #sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        logits_seq = out[1] # <YOUR CODE>\n",
    "\n",
    "        # prepend first_logits to logits_seq\n",
    "        logits_seq = tf.concat((first_logits[tf.newaxis], logits_seq), axis = 0) #<...>\n",
    "\n",
    "        # Make sure you convert logits_seq from\n",
    "        # [time, batch, voc_size] to [batch, time, voc_size]\n",
    "        logits_seq = tf.transpose(logits_seq, perm = [1, 0, 2]) #<...>\n",
    "\n",
    "        return logits_seq\n",
    "\n",
    "    def compute_loss(self, inp, out, **flags):\n",
    "        \n",
    "        mask = infer_mask(out, out_voc.eos_ix)    \n",
    "        logits_seq = self.compute_logits(inp, out, **flags)\n",
    "\n",
    "        # Compute loss as per instructions above\n",
    "        # <YOUR CODE>\n",
    "\n",
    "        prob_seq = tf.nn.softmax(logits_seq)\n",
    "        out_one_hot = tf.one_hot(out, len(self.out_voc))\n",
    "\n",
    "        prob_seq_masked = tf.boolean_mask(prob_seq, mask)\n",
    "        out_one_hot_masked = tf.boolean_mask(out_one_hot, mask)\n",
    "        prob_seq_out = tf.boolean_mask(prob_seq_masked, out_one_hot_masked)\n",
    "        loss = tf.reduce_mean(-tf.log(prob_seq_out))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def translate_lines(self, inp_lines, max_len=100):\n",
    "        \"\"\"\n",
    "        Translates a list of lines by greedily selecting most likely next token at each step\n",
    "        :returns: a list of output lines, a sequence of model states at each step\n",
    "        \"\"\"\n",
    "        state = sess.run(self.initial_state, {self.inp: self.inp_voc.to_matrix(inp_lines)})\n",
    "        outputs = [[self.out_voc.bos_ix] for _ in range(len(inp_lines))]\n",
    "        all_states = [state]\n",
    "        finished = [False] * len(inp_lines)\n",
    "\n",
    "        for t in range(max_len):\n",
    "            state, logits = sess.run([self.next_state, self.next_logits],\n",
    "                                     {**dict(zip(self.prev_state, state)),\n",
    "                                      self.prev_tokens: [out_i[-1] for out_i in outputs]})\n",
    "            next_tokens = np.argmax(logits, axis=-1)\n",
    "            all_states.append(state)\n",
    "            for i in range(len(next_tokens)):\n",
    "                outputs[i].append(next_tokens[i])\n",
    "                finished[i] |= next_tokens[i] == self.out_voc.eos_ix\n",
    "        return self.out_voc.to_lines(outputs), all_states\n",
    "    \n",
    "    def get_prefix(self, line):\n",
    "        assert type(line) == str\n",
    "        \n",
    "        res = ''\n",
    "        \n",
    "        VOWEL_ID = 1\n",
    "        CONS_ID = 2\n",
    "        prev_ch_id = 0\n",
    "        \n",
    "        for ch in line.lower():\n",
    "            ch_id = 0\n",
    "            if ch in self.vowels:\n",
    "                ch_id = VOWEL_ID\n",
    "            elif ch in self.consonants:\n",
    "                ch_id = CONS_ID\n",
    "            \n",
    "            if ch_id:\n",
    "                res += ch\n",
    "                \n",
    "            if prev_ch_id == 0:\n",
    "                prev_ch_id = ch_id\n",
    "            elif prev_ch_id != ch_id:\n",
    "                break\n",
    "                \n",
    "        return res\n",
    "\n",
    "    def has_word(self, line):\n",
    "        assert type(line) == str\n",
    "        \n",
    "        prev_in_word = False\n",
    "        for ch in line.lower():\n",
    "            in_word = ch in self.vowels or ch in self.consonants\n",
    "            if prev_in_word and not in_word:\n",
    "                return True\n",
    "            prev_in_word = in_word\n",
    "        return False\n",
    "\n",
    "    def get_word(self, line):\n",
    "        assert type(line) == str\n",
    "        \n",
    "        res = ''\n",
    "        prev_in_word = False\n",
    "        for ch in line.lower():\n",
    "            in_word = ch in self.vowels or ch in self.consonants\n",
    "            if in_word:\n",
    "                res += ch\n",
    "            elif prev_in_word:\n",
    "                return res\n",
    "            prev_in_word = in_word\n",
    "            \n",
    "        return res\n",
    "    \n",
    "    def translate_line_with_rhyme(self,\n",
    "                                  inp_line,\n",
    "                                  rhyme_line,\n",
    "                                  rhyme_type,\n",
    "                                  max_len,\n",
    "                                  max_rhyme_retry_count):\n",
    "        \n",
    "        def tokens_to_line(toks):\n",
    "            return ''.join(self.out_voc.to_lines([toks])[0].replace('@@ ', ''))\n",
    "        \n",
    "        check_rhyme = rhyme_line is not None\n",
    "        \n",
    "        if check_rhyme:\n",
    "            if rhyme_type == RHYME_PREFIX:\n",
    "                rhyme_prefix = self.get_prefix(rhyme_line)\n",
    "                print(' rhyme prefix: \"{}\"'.format(''.join(reversed(rhyme_prefix))))\n",
    "            elif rhyme_type == RHYME_WORD:\n",
    "                rhyme_word = ''.join(reversed(self.get_word(rhyme_line)))\n",
    "                print(' rhyme word: \"{}\"'.format(rhyme_word))\n",
    "            else:\n",
    "                assert False\n",
    "        \n",
    "        for rhyme_retry_idx in range(max_rhyme_retry_count):\n",
    "            \n",
    "            rhyme_can_retry = rhyme_retry_idx < max_rhyme_retry_count - 1\n",
    "            rhyme_state = None if check_rhyme else True\n",
    "            \n",
    "            state = sess.run(self.initial_state, {self.inp: self.inp_voc.to_matrix([inp_line])})\n",
    "            output = [self.out_voc.bos_ix]\n",
    "\n",
    "            for t in range(max_len):\n",
    "                state, logits, softmax = sess.run([self.next_state,\n",
    "                                                   self.next_logits,\n",
    "                                                   self.next_softmax],\n",
    "                                                  {**dict(zip(self.prev_state, state)),\n",
    "                                                   self.prev_tokens: [output[-1]]})\n",
    "                \n",
    "                probs = softmax[0] ** (1. / 0.5)\n",
    "                probs /= probs.sum()\n",
    "                # sample from softmax with temperature\n",
    "                next_token = np.random.choice(len(probs), p = probs)\n",
    "                output.append(next_token)\n",
    "                \n",
    "                eos_token = next_token == self.out_voc.eos_ix\n",
    "                \n",
    "                if rhyme_can_retry and rhyme_state is None:\n",
    "                    \n",
    "                    line = tokens_to_line(output)\n",
    "                    \n",
    "                    if eos_token or self.has_word(line):\n",
    "                        \n",
    "                        if rhyme_type == RHYME_PREFIX:\n",
    "                            \n",
    "                            prefix = self.get_prefix(line)\n",
    "                            print('  line prefix: \"{}\"'.format(''.join(reversed(prefix))))\n",
    "                            \n",
    "                            pref_len = min(len(rhyme_prefix), len(prefix))\n",
    "                            rhyme_state = prefix[:pref_len] == rhyme_prefix[:pref_len]\n",
    "                            \n",
    "                        elif rhyme_type == RHYME_WORD:\n",
    "                            \n",
    "                            word = ''.join(reversed(self.get_word(line)))\n",
    "                            print('  line word: \"{}\"'.format(word))\n",
    "                            \n",
    "                            rhyme_state = self.rupo_engine.is_rhyme(rhyme_word, word)\n",
    "                            \n",
    "                        else:\n",
    "                            assert False\n",
    "\n",
    "                            \n",
    "                        \n",
    "                        if not rhyme_state: # Rhyme is bad and can retry\n",
    "                            break\n",
    "                            \n",
    "                        print('  rhyme found!')\n",
    "                        \n",
    "                if eos_token:\n",
    "                    break\n",
    "            \n",
    "            if rhyme_state: # Rhyme is OK\n",
    "                break\n",
    "        \n",
    "        return tokens_to_line(output)\n",
    "    \n",
    "    \n",
    "    def translate_lines_with_rhyme(self,\n",
    "                                   inp_lines,\n",
    "                                   rhyme_type = RHYME_WORD,\n",
    "                                   max_len = 100,\n",
    "                                   max_rhyme_retry_count = 20):\n",
    "\n",
    "        \n",
    "        translated = []\n",
    "        for i in range(len(inp_lines)):\n",
    "            \n",
    "            inp_line = inp_lines[i]\n",
    "            rhyme_line = translated[-1] if i % 2 == 1 else None\n",
    "            \n",
    "            \n",
    "            line = self.translate_line_with_rhyme(inp_lines[i],\n",
    "                                                  rhyme_line,\n",
    "                                                  rhyme_type,\n",
    "                                                  max_len,\n",
    "                                                  max_rhyme_retry_count)\n",
    "\n",
    "            translated.append(line)\n",
    "            \n",
    "        return translated\n",
    "\n",
    "    \n",
    "    def dump(self, filename):\n",
    "        \n",
    "        values = {'name': self.name,\n",
    "                  'inp_voc': self.inp_voc,\n",
    "                  'out_voc': self.out_voc,\n",
    "                  'emb_size': self.emb_size,\n",
    "                  'hid_size': self.hid_size,\n",
    "                  #'attn_size': self.attn_size,\n",
    "                  'emb_inp_weights': self.emb_inp.get_weights(),\n",
    "                  'emb_out_weights': self.emb_out.get_weights(),\n",
    "                  #'enc0_weights': self.enc0.get_weights(),\n",
    "                  'enc_lstm_fw_cell_weights': self.enc_lstm_fw_cell.get_weights(),\n",
    "                  'enc_lstm_bw_cell_weights': self.enc_lstm_bw_cell.get_weights(),\n",
    "                  'dec0_weights': self.dec0.get_weights(),\n",
    "                  'dec_start_weights': self.dec_start.get_weights(),\n",
    "                  'dense_weights': self.dense.get_weights(),\n",
    "                  'logits_weights': self.logits.get_weights(),\n",
    "                  'attn__linear_e_weights': self.attention.linear_e.get_weights(),\n",
    "                  'attn__linear_d_weights': self.attention.linear_d.get_weights(),\n",
    "                  'attn__linear_out_weights': self.attention.linear_out.get_weights()}\n",
    "        pickle.dump(values, open(filename, 'wb'))\n",
    "    \n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            values = pickle.load(f)\n",
    "        self.initialize(values['name'], values['inp_voc'], values['out_voc'],\n",
    "                        values['emb_size'], values['hid_size']) #, values['attn_size'])\n",
    "        self.emb_inp.set_weights(values['emb_inp_weights'])\n",
    "        self.emb_out.set_weights(values['emb_out_weights'])\n",
    "        #self.enc0.set_weights(values['enc0_weights'])\n",
    "        self.enc_lstm_fw_cell.set_weights(values['enc_lstm_fw_cell_weights'])\n",
    "        self.enc_lstm_bw_cell.set_weights(values['enc_lstm_bw_cell_weights'])\n",
    "        self.dec0.set_weights(values['dec0_weights'])\n",
    "        self.dec_start.set_weights(values['dec_start_weights'])\n",
    "        self.dense.set_weights(values['dense_weights'])\n",
    "        self.logits.set_weights(values['logits_weights'])\n",
    "        self.attention.linear_e.set_weights(values['attn__linear_e_weights'])\n",
    "        self.attention.linear_d.set_weights(values['attn__linear_d_weights'])\n",
    "        self.attention.linear_out.set_weights(values['attn__linear_out_weights'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "def compute_bleu(model, inp_lines, out_lines, bpe_sep='@@ ', **flags):\n",
    "    \"\"\" Estimates corpora-level BLEU score of model's translations\n",
    "        given inp and reference out \"\"\"\n",
    "    translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "    # Note: if you experience out-of-memory error,\n",
    "    # split input lines into batches and translate separately\n",
    "    return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n",
    "\n",
    "def compute_bleu_large(model, inp_lines, out_lines):\n",
    "    batch_size = 256\n",
    "    result = 0.0\n",
    "    for i in range(0, inp_lines.shape[0], batch_size):\n",
    "        current_bleu = compute_bleu(model,\n",
    "                                    inp_lines[i:i+batch_size],\n",
    "                                    out_lines[i:i+batch_size])\n",
    "        current_bleu *= min(i + batch_size, inp_lines.shape[0]) - i\n",
    "        result += current_bleu\n",
    "    result /= inp_lines.shape[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reversed(line):\n",
    "    return ''.join(reversed(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fac597647f0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fac597648d0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = AttentiveModel(None,\n",
    "                       'model_translator_attn_reversed_amalgama_subtitles_09_03_2019',\n",
    "                       inp_voc,\n",
    "                       out_voc,\n",
    "                       emb_size=128,\n",
    "                       hid_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "inp = tf.placeholder('int32', [None, None])\n",
    "out = tf.placeholder('int32', [None, None])\n",
    "\n",
    "loss = model.compute_loss(inp, out)\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "K.get_session() # To not reset optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "metrics = {'train_loss': [], 'dev_bleu': []}\n",
    "sess.run(tf.global_variables_initializer())\n",
    "batch_size = 32\n",
    "dev_batch_size = 128\n",
    "\n",
    "def train_model(train_inp, train_out, dev_inp, dev_out, iters):\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    for _ in trange(iters):\n",
    "    #for _ in range(iters):\n",
    "        step = len(metrics['train_loss']) + 1\n",
    "        batch_ix = np.random.randint(len(train_inp), size=batch_size)\n",
    "        feed_dict = {\n",
    "            inp: inp_voc.to_matrix(train_inp[batch_ix]),\n",
    "            out: out_voc.to_matrix(train_out[batch_ix]),\n",
    "        }\n",
    "\n",
    "        loss_t, _ = sess.run([loss, train_step], feed_dict)\n",
    "        metrics['train_loss'].append((step, loss_t))\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            batch_dev_ix = np.random.randint(len(dev_inp), size=dev_batch_size)\n",
    "            metrics['dev_bleu'].append((step, compute_bleu(model,\n",
    "                                                           dev_inp[batch_dev_ix],\n",
    "                                                           dev_out[batch_dev_ix])))\n",
    "\n",
    "            clear_output(True)\n",
    "            plt.figure(figsize=(12,4))\n",
    "            for i, (name, history) in enumerate(sorted(metrics.items())):\n",
    "                plt.subplot(1, len(metrics), i + 1)\n",
    "                plt.title(name)\n",
    "                plt.plot(*zip(*history))\n",
    "                plt.grid()\n",
    "            plt.show()\n",
    "            print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0)[1],\n",
    "                  flush=True)\n",
    "        if step % 10000 == 0:\n",
    "            model.dump('{}.pkl'.format(model.name))\n",
    "    end = datetime.datetime.now()\n",
    "    print('Execution time: {}'.format(end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss=2.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 497232/550001 [102:03:07<10:49:49,  1.35it/s]"
     ]
    }
   ],
   "source": [
    "train_model(train_inp,\n",
    "            train_out,\n",
    "            dev_inp,\n",
    "            dev_out,\n",
    "            550001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dev_bleu = compute_bleu_large(model, dev_inp, dev_out)\n",
    "print('dev_bleu', dev_bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us dump current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let us fine-tune our model with only Amalgama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(amalgama_train_inp,\n",
    "            amalgama_train_out,\n",
    "            amalgama_dev_inp,\n",
    "            amalgama_dev_out,\n",
    "            150001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "amalgama_dev_bleu = compute_bleu_large(model, amalgama_dev_inp, amalgama_dev_out)\n",
    "print('amalgama_dev_bleu', amalgama_dev_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_dev_song = dev_songs[random.randint(1, len(dev_songs) - 1)][0]\n",
    "source = [pair[0] for pair in random_dev_song]\n",
    "target = [pair[1] for pair in random_dev_song]\n",
    "predicted = model_loaded.translate_lines(source)[0]\n",
    "for i in range(len(source)):\n",
    "    print('{}|{}|{}'.format(get_reversed(source[i]),\n",
    "                            get_reversed(target[i]),\n",
    "                            get_reversed(predicted[i])))\n",
    "print('-----------------------')\n",
    "print('\\n'.join(map(get_reversed, source)))\n",
    "print('-----------------------')\n",
    "print('\\n'.join(map(get_reversed, target)))\n",
    "print('-----------------------')\n",
    "print('\\n'.join(map(get_reversed, predicted)))\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
