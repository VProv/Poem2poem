{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import codecs\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('/srv/hd6/data'): # shad-gpu\n",
    "    data_root_dir = '/srv/hd6/data/Poem2Poem/data'\n",
    "    bpe_root_dir = '/srv/hd7/data/aklyopova'\n",
    "elif os.path.isdir('/data'): # shad-almaren\n",
    "    data_root_dir = 'data'\n",
    "    bpe_root_dir = data_root_dir\n",
    "else:\n",
    "    assert False\n",
    "assert os.path.isdir(data_root_dir)\n",
    "assert os.path.isdir(bpe_root_dir)\n",
    "    \n",
    "amalgama_fname = data_root_dir + '/ParallelEnRu/Amalgama/amalgama-reversed-song-translations.jsonl'\n",
    "subtitles_fname = data_root_dir + '/ParallelEnRu/OpenSubtitlesv2018/en-ru-reversed.jsonl'\n",
    "bpe_dir_name = bpe_root_dir + '/translator_with_pentameter_16_03_2019'\n",
    "SHAKESPEARE_SONNETS_PARALLEL_PATH = data_root_dir + \\\n",
    "'/Sonnets/ShakespeareSonnets/shakespeare-sonnets-en-ru-marshak.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(songs) 20000\n",
      "errors 0\n",
      "len(train_songs) 18000\n",
      "len(dev_songs) 2000\n",
      "[[['niks ym gnihcuot ,deb ni gniyL', ',ежок йеовс к ьсюасакирп ,илетсоп в ажеЛ'], [\"gnipeels t'nerew uoy hsiw I doG hO\", '.ьшипс ыт отч ,ьлаж ,ежоБ'], ['niaga em ssik ot ,spil ruoy rof gnol I', ',яулецоп ялд мабуг миовт к ьсюажилбирп Я'], [\"?gnihca s'ydob ym wonk uoy t'noD\", '?тирог олет еом отч ,ьшеанз ен ыт евзаР'], [']ehtaerB[', ']еинахыД['], [',yap ot ecirp elttil a evah syawla ew smeeS', ',ьтиталп есв аз ынжлод адгесв ым ,ястежаК'], [\"evol ni gnillaF m'I ,yap ot ecirP\", ',ьсюялбюлв я - ,ьтиталП'], ['edaf ot strats ,strats lla tI', '...тен ан ьтидохс оннепетсоп теаничан есв ,теаничан есв адгот И'], ['syob elttil dab dna ,slrig daB', 'инрап еихолп и икночвед еихолП'], [\"reverof tsal t'noW\", ',адгесван етсемв тудуб ен адгокиН'], ['syob elttil doog dna ,slrig dooG tuB', 'инрап еишорох и икночвед еишорох оН'], ['rehtegot evol ekam lliW', '...агурд гурд ьтибюл тудуБ'], ['ekawa eil I sa ,ecaf ruoy ta kool I', ',юлпс ен отч умотоп ,оцил еовт ан юртомс Я'], [\"resolc gnivom ylwols s'ydob yM\", '.ебет к ястеживд оннелдем олет еоМ'], ['gel ruoy no dnah yM', ',егон йеовт ан акур яоМ'], ['yaw sti no htuom yM', ',огеовт олоко тор йоМ'], [\"revo uoy nrut tsuj ll'I ,ybab hO\", '...ябет ьтунревереп учох отсорп я ,шылаМ'], [',yap ot ecirp elttil a evah syawla ew smeeS', '.ьтиталп есв аз ынжлод адгесв ым ,ястежаК'], [\"evol ni gnillaF m'I )hu( ,yap ot ecirP\", ',ьсюялбюлв я )ха( ьтиталП'], ['ehca ot strats ,strats lla tI', '...тен ан ьтидохс оннепетсоп теаничан есв ,теаничан есв адгот И'], ['syob elttil dab dna ,slrig daB', 'инрап еихолп и икночвед еихолП'], [\"reverof tsal t'noW\", ',адгесван етсемв тудуб ен адгокиН'], [')syob( syob elttil doog dna ,slrig dooG tuB', 'инрап еишорох и икночвед еишорох оН'], ['...rehtegot evol ekam lliW', '...агурд гурд ьтибюл тудуБ'], [',rehtegot evol ,rehtegot evoL', 'агурд гурд ьтибюл ,агурд гурд ьтибюЛ'], [',rehtegot evol ,rehtegot evoL', 'агурд гурд ьтибюл ,агурд гурд ьтибюЛ'], ['...rehtegot evoL', '...агурд гурд ьтибюЛ'], ['siht ekil I ?siht ekil uoy oD', 'ад – енМ ?ястиварн ебеТ'], ['thgirla uoy tnaw I', ',еивтсьловоду ебет ьтиватсод учох Я'], ['?em hcuot annaw uoy oD', '?енм ок ясьтунсокирп ьшечох ыТ'], ['siht ekil I', ',ястиварн енМ'], ['?siht eldnah uoy naC', '?митэ с ясьтиварпс ьшежом ыТ'], ['siht ekil I', ',ястиварн енМ'], [\",nwod ti wols annog er'eW\", '....ясьтипорот медуб ен адукин ыМ'], ['tib elttil a tsuJ', '...огонмен месвоС'], [\"niks ym gnihcuot ,deb ni gniyl m'I\", ',ежок йеовс к ьсюасакирп ,илетсоп в ажеЛ'], [\"ybab ti ekat t'nac tsuj I\", '.шылам ,угом ен кат ешьлоб Я'], ['..em ot repsihw ,seye ruoy nepO', '..енм ичпешоп и азалг йорктО'], ['niaga ti od ,niaga ti oD', '...авонс и авонс отэ йалеД'], ['syob elttil dab dna ,slrig daB', 'инрап еихолп и икночвед еихолП'], [\"reverof tsal t'noW\", ',адгесван етсемв тудуб ен адгокиН'], [')syob( syob elttil doog dna ,slrig dooG tuB', ')инрап( инрап еишорох и икночвед еишорох оН'], ['rehtegot evol ekam lliW', '...агурд гурд ьтибюл тудуБ'], ['syob elttil dab dna ,slrig daB', 'инрап еихолп и икночвед еихолП'], [\"reverof tsal t'noW\", ',адгесван етсемв тудуб ен адгокиН'], [')syob( syob elttil doog dna ,slrig dooG tuB', ')инрап( инрап еишорох и икночвед еишорох оН'], ['rehtegot evol ekam lliW', ',агурд гурд ьтибюл тудуБ'], [',rehtegot evol ,rehtegot evoL', ',агурд гурд ьтибюл ,агурд гурд ьтибюЛ'], ['...rehtegot evoL', '...агурд гурд ьтибюЛ'], [\"?siht ekil uoy od ,doog s'tahT\", '?ястиварн ебет ,онссалК'], ['nwod ti wols annog ,haeY', ',ясьтипорот медуб ен адукин ым ,аД'], [\"rehtegot evol ekam ll'eW\", '...юьвобюл ясмемйаз ыМ']]]\n",
      "CPU times: user 5.53 s, sys: 372 ms, total: 5.9 s\n",
      "Wall time: 5.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_amalgama_songs_subset(dataset_fname):\n",
    "    songs = []\n",
    "    errors = 0\n",
    "    count = 0\n",
    "    with codecs.open(dataset_fname,\n",
    "                     mode = 'r',\n",
    "                     encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            count += 1\n",
    "            if count > 20000:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if line == '':\n",
    "                continue\n",
    "            try:\n",
    "                song = json.loads(line)\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                print(e, '\\n', line)\n",
    "            songs.append([[line['texts'] \\\n",
    "                           for line in translation['lines'] \\\n",
    "                           if 'is_sub_caption' not in line \\\n",
    "                              and line['texts'] is not None] \\\n",
    "                          for translation in song['translations']])\n",
    "    return songs, errors\n",
    "    \n",
    "songs, errors = get_amalgama_songs_subset(amalgama_fname)\n",
    "train_songs, dev_songs = train_test_split(songs, test_size = 0.1, random_state = 1)\n",
    "print('len(songs)', len(songs))\n",
    "print('errors', errors)\n",
    "print('len(train_songs)', len(train_songs))\n",
    "print('len(dev_songs)', len(dev_songs))\n",
    "print(train_songs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RUSSIAN_CHARS\n",
      " {'п', 'Т', 'ь', 'С', 'л', 'ю', 'в', 'Ъ', 'И', 'Г', 'Ь', 'А', 'к', 'Х', 'а', 'м', 'ф', 'х', 'Б', 'К', 'Н', 'Р', 'Л', 'М', 'Э', 'р', 'е', 'ъ', 'У', 'Ф', 'ц', ' ', 'ё', 'П', 'Ш', 'з', 'Й', 'э', 'ч', 'В', 'Ю', 'т', 'у', 'щ', 'я', 'й', 'Д', 'Ч', 'ы', 'Е', 'Ы', 'д', 'Щ', 'г', 'с', 'ж', 'ш', '@', 'О', 'и', 'Ё', 'б', 'о', '-', 'Ж', 'Я', 'н', 'Ц', 'З'} \n",
      "\n",
      "len(amalgama_train_lines_foreign) 705119\n",
      "len(amalgama_train_lines_russian) 705119\n",
      "len(amalgama_dev_lines_foreign) 79183\n",
      "len(amalgama_dev_lines_russian) 79183\n",
      "CPU times: user 14.3 s, sys: 108 ms, total: 14.4 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def is_english(line):\n",
    "    \n",
    "    letters = re.sub(r'\\W', '', line.lower())\n",
    "    return len(letters) > 0 and \\\n",
    "           all([ord('a') <= ord(c) <= ord('z') for c in letters])\n",
    "\n",
    "\n",
    "def get_lines_from_amalgama_songs(songs,\n",
    "                                  possible_source_chars,\n",
    "                                  possible_target_chars):\n",
    "    lines_foreign = []\n",
    "    lines_russian = []\n",
    "    for song in songs:\n",
    "        for translation in song:\n",
    "            for line_pair in translation:\n",
    "                if line_pair[0] is None or line_pair[1] is None:\n",
    "                    continue\n",
    "                if not is_english(line_pair[0]):\n",
    "                    continue\n",
    "                line_pair[0] = line_pair[0].lower()\n",
    "                line_pair[1] = line_pair[1].lower()\n",
    "                line_pair[0] = u''.join([c for c in line_pair[0] if \\\n",
    "                                         c in possible_source_chars])\n",
    "                line_pair[1] = u''.join([c for c in line_pair[1] if \\\n",
    "                                         c in possible_target_chars])\n",
    "                lines_foreign.append(line_pair[0])\n",
    "                lines_russian.append(line_pair[1])\n",
    "    return lines_foreign, lines_russian\n",
    "\n",
    "ENGLISH_CHARS = set([chr(n) for n in range(ord('A'), ord('Z') + 1)] + \\\n",
    "                    [chr(n) for n in range(ord('a'), ord('z') + 1)] + [' ', '@', '-', \"'\"])\n",
    "RUSSIAN_CHARS = set([chr(n) for n in range(ord('А'), ord('Я') + 1)] + \\\n",
    "                    [chr(n) for n in range(ord('а'), ord('я') + 1)] + [' ', '@', '-', 'Ё', 'ё'])\n",
    "print('\\nRUSSIAN_CHARS\\n', RUSSIAN_CHARS, '\\n')\n",
    "\n",
    "(amalgama_train_lines_foreign,\n",
    " amalgama_train_lines_russian) = get_lines_from_amalgama_songs(train_songs,\n",
    "                                                               ENGLISH_CHARS,\n",
    "                                                               RUSSIAN_CHARS)\n",
    "print('len(amalgama_train_lines_foreign)', len(amalgama_train_lines_foreign))\n",
    "print('len(amalgama_train_lines_russian)', len(amalgama_train_lines_russian))\n",
    "(amalgama_dev_lines_foreign,\n",
    " amalgama_dev_lines_russian) = get_lines_from_amalgama_songs(dev_songs,\n",
    "                                                             ENGLISH_CHARS,\n",
    "                                                             RUSSIAN_CHARS)\n",
    "print('len(amalgama_dev_lines_foreign)', len(amalgama_dev_lines_foreign))\n",
    "print('len(amalgama_dev_lines_russian)', len(amalgama_dev_lines_russian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ah ah ah ah ah aha\n",
      "ah ah ah ah ah aha\n",
      "niaga aes ot tuo og i ereh\n",
      "riah ym sllif enihsnus eht\n",
      "\n",
      "а-а-а-а-аха\n",
      "а-а-а-а-аха\n",
      "юром к уди авонс я тов и\n",
      "ысолов мецнлос ытилаз\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(amalgama_train_lines_foreign[:4]))\n",
    "print()\n",
    "print('\\n'.join(amalgama_train_lines_russian[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 18s, sys: 896 ms, total: 2min 19s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "tokenizer = WordPunctTokenizer()\n",
    "def tokenize(x):\n",
    "    return ' '.join(tokenizer.tokenize(x.lower()))\n",
    "\n",
    "\n",
    "def def_get_BPE_dicts(train_lines_foreign, train_lines_russian):\n",
    "\n",
    "    \n",
    "    with codecs.open(os.path.join(bpe_dir_name, 'train_lines_foreign'),\n",
    "                     mode = 'w',\n",
    "                     encoding = 'utf-8') as f:\n",
    "        f.write('\\n'.join(map(tokenize, train_lines_foreign)))\n",
    "    with codecs.open(os.path.join(bpe_dir_name, 'train_lines_russian'),\n",
    "                     mode = 'w',\n",
    "                     encoding = 'utf-8') as f:\n",
    "        f.write('\\n'.join(map(tokenize, train_lines_russian)))\n",
    "\n",
    "    bpe = {}\n",
    "    for lang in ['foreign', 'russian']:\n",
    "        learn_bpe(codecs.open(os.path.join(bpe_dir_name,\n",
    "                                           'train_lines_{}'.format(lang)),\n",
    "                              mode = 'r',\n",
    "                              encoding = 'utf-8'),\n",
    "                  codecs.open(os.path.join(bpe_dir_name,\n",
    "                                           'bpe_rules_{}_40000'.format(lang)),\n",
    "                              mode = 'w',\n",
    "                              encoding = 'utf-8'),\n",
    "                  num_symbols = 40000)\n",
    "        bpe[lang] = BPE(codecs.open(os.path.join(bpe_dir_name,\n",
    "                                                 'bpe_rules_{}_40000'.format(lang)),\n",
    "                                    mode = 'r',\n",
    "                                    encoding = 'utf-8'))\n",
    "    return bpe\n",
    "\n",
    "bpe = def_get_BPE_dicts(amalgama_train_lines_foreign, amalgama_train_lines_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.6 s, sys: 116 ms, total: 25.7 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "amalgama_train_lines_foreign_bpe = \\\n",
    "[bpe['foreign'].process_line(line.strip()) for line in amalgama_train_lines_foreign]\n",
    "amalgama_dev_lines_foreign_bpe = \\\n",
    "[bpe['foreign'].process_line(line.strip()) for line in amalgama_dev_lines_foreign]\n",
    "\n",
    "amalgama_train_lines_russian_bpe = \\\n",
    "[bpe['russian'].process_line(line.strip()) for line in amalgama_train_lines_russian]\n",
    "amalgama_dev_lines_russian_bpe = \\\n",
    "[bpe['russian'].process_line(line.strip()) for line in amalgama_dev_lines_russian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 676 ms, sys: 412 ms, total: 1.09 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_inp = np.array([line[:150] for line in amalgama_train_lines_foreign_bpe])\n",
    "train_out = np.array([line[:150] for line in amalgama_train_lines_russian_bpe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_inp = np.array([line[:150] for line in amalgama_dev_lines_foreign_bpe])\n",
    "dev_out = np.array([line[:150] for line in amalgama_dev_lines_russian_bpe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "['hguorht swolb mrots eht sa hctaw' 'uoy deen i dna'\n",
      " 'snwod dna spu eht rof uoy em evag dog esuac'\n",
      " 'tbuod fo syad eht rof uoy em evag dog'\n",
      " \"yaw ym tsol ev@@ '@@ i kniht i nehw rof dna\"]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "words to ids (0 = bos, 1 = eos):\n",
      "[[    0 12753 31222 16834  6051 25594 12603     1     1     1     1     1\n",
      "      1]\n",
      " [    0 34882  2797 13227  4332     1     1     1     1     1     1     1\n",
      "      1]\n",
      " [    0 29099  4332 29503  6051 25076 34882  7115  9820  4631  8884     1\n",
      "      1]\n",
      " [    0 31523 10354 31260  6051 25076 34882  7115  9820  4631     1     1\n",
      "      1]\n",
      " [    0 35661 36522 34210  9811     6 13227 14732 13227 17820 25076  4332\n",
      "      1]]\n",
      "\n",
      "back to words\n",
      "['hguorht swolb mrots eht sa hctaw', 'uoy deen i dna', 'snwod dna spu eht rof uoy em evag dog esuac', 'tbuod fo syad eht rof uoy em evag dog', \"yaw ym tsol ev@@ '@@ i kniht i nehw rof dna\"]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# utils.py is copied from Homework 4 assignment as is\n",
    "from utils import Vocab\n",
    "inp_voc = Vocab.from_lines(train_inp)\n",
    "out_voc = Vocab.from_lines(train_out)\n",
    "# Here's how you cast lines into ids and backwards.\n",
    "batch_lines = dev_inp[5:10]\n",
    "batch_ids = inp_voc.to_matrix(batch_lines)\n",
    "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
    "\n",
    "print(\"lines\")\n",
    "print(batch_lines)\n",
    "print(type(batch_lines))\n",
    "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
    "print(batch_ids)\n",
    "print(\"\\nback to words\")\n",
    "print(batch_lines_restored)\n",
    "print(type(batch_lines_restored))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonnet generally consists of 14 lines but some of them more, like 15 in this Shakeapeare sonnet:\n",
    "\n",
    "```\n",
    "The forward violet thus did I chide,\n",
    "Sweet thief, whence didst thou steal thy sweet that smells,\n",
    "If not from my love’s breath? The purple pride\n",
    "Which on thy soft check for complexion dwells,\n",
    "In my love’s veins thou hast too grossly dyed.\n",
    "The lily I condemned for thy hand,\n",
    "And buds of marjoram had stol’n thy hair,\n",
    "The roses fearfully on thorns did stand,\n",
    "One blushing shame, another white despair:\n",
    "A third nor red, nor white, had stol’n of both,\n",
    "And to his robbery had annexed thy breath,\n",
    "But for his theft in pride of all his growth\n",
    "A vengeful canker eat him up to death.\n",
    "More flowers I noted, yet I none could see,\n",
    "But sweet, or colour it had stol’n from thee.```\n",
    "\n",
    "We will drop such sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sonnet_lines_english) 2128\n",
      "len(sonnet_lines_russian) 2128\n",
      "non_fourteen_lines 2\n",
      "Why lov’st thou that which thou receiv’st not gladly,\n",
      "Зачем же любишь то, что так печально,\n",
      "When I perceive that men as plants increase,\n",
      "Что нас, как всходы нежные растений,\n",
      "------------------\n",
      "но вижу я в твоих глазах предвестье\n",
      "уверенность и власть греховных сил\n"
     ]
    }
   ],
   "source": [
    "def get_sonnets_lines_parallel(fname):\n",
    "    sonnet_lines_english = []\n",
    "    sonnet_lines_russian = []\n",
    "    non_fourteen_lines = 0\n",
    "    with codecs.open(fname, mode = 'r', encoding = 'utf-8') as f:\n",
    "        sonnets = f.read().replace('\\r', '').split('\\n===\\n')\n",
    "    for sonnet in sonnets:\n",
    "        en, ru = sonnet.split('\\n---\\n')\n",
    "        en = [line.strip() for line in en.split('\\n') if line.strip() != '']\n",
    "        ru = [line.strip() for line in ru.split('\\n') if line.strip() != '']\n",
    "        if len(en) != 14 or len(ru) != 14:\n",
    "            non_fourteen_lines += 1\n",
    "            continue\n",
    "        sonnet_lines_english.extend(en)\n",
    "        sonnet_lines_russian.extend(ru)\n",
    "    assert len(sonnet_lines_english) == len(sonnet_lines_russian)\n",
    "    return sonnet_lines_english, sonnet_lines_russian, non_fourteen_lines\n",
    "\n",
    "import re\n",
    "def remove_punc_and_lower(line):\n",
    "    line = re.sub(r'[^\\w\\s]', '', line)\n",
    "    line = re.sub(r'\\s+', ' ', line)\n",
    "    return line.strip().lower()\n",
    "\n",
    "(sonnet_lines_english,\n",
    " sonnet_lines_russian,\n",
    " non_fourteen_lines) = \\\n",
    "get_sonnets_lines_parallel(SHAKESPEARE_SONNETS_PARALLEL_PATH)\n",
    "print('len(sonnet_lines_english)', len(sonnet_lines_english))\n",
    "print('len(sonnet_lines_russian)', len(sonnet_lines_russian))\n",
    "print('non_fourteen_lines', non_fourteen_lines)\n",
    "print(sonnet_lines_english[100])\n",
    "print(sonnet_lines_russian[100])\n",
    "print(sonnet_lines_english[200])\n",
    "print(sonnet_lines_russian[200])\n",
    "\n",
    "(train_sonnet_lines_english,\n",
    " dev_sonnet_lines_english,\n",
    " train_sonnet_lines_russian,\n",
    " dev_sonnet_lines_russian) = train_test_split([remove_punc_and_lower(line) for \\\n",
    "                                               line in sonnet_lines_english],\n",
    "                                              [remove_punc_and_lower(line) for \\\n",
    "                                               line in sonnet_lines_russian],\n",
    "                                              test_size = 0.15,\n",
    "                                              random_state = 1)\n",
    "print('------------------')\n",
    "print(train_sonnet_lines_russian[0])\n",
    "print(dev_sonnet_lines_russian[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, some lines don't correspond to -+-+-+-+-+ pattern but correspond to -+-+-+-+-+-\n",
    "\n",
    "Let us try to filter out non-10 syllables lines and see how much lines will remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808\n",
      "320\n",
      "1184\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "def count_syllables_russian(line):\n",
    "    vowels = 'аеёиоуыэюяАЕЁИОУЫЭЮЯ'\n",
    "    return len([c for c in line if c in vowels])\n",
    "\n",
    "train_sonnet_lines_russian_ten_syllables = \\\n",
    "[line for line in train_sonnet_lines_russian if \\\n",
    " count_syllables_russian(line) == 10]\n",
    "\n",
    "dev_sonnet_lines_russian_ten_syllables = \\\n",
    "[line for line in dev_sonnet_lines_russian if \\\n",
    " count_syllables_russian(line) == 10]\n",
    "\n",
    "print(len(train_sonnet_lines_russian))\n",
    "print(len(dev_sonnet_lines_russian))\n",
    "print(len(train_sonnet_lines_russian_ten_syllables))\n",
    "print(len(dev_sonnet_lines_russian_ten_syllables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too little lines remain if we filter them by syllables count thus let us not filter them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sonnet_lines_russian_stresses = \\\n",
    "[[i % 2 == 1 for i in range(count_syllables_russian(line))] \\\n",
    " for line in train_sonnet_lines_russian]\n",
    "dev_sonnet_lines_russian_stresses = \\\n",
    "[[i % 2 == 1 for i in range(count_syllables_russian(line))] \\\n",
    " for line in dev_sonnet_lines_russian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=5\n",
    "import tensorflow as tf\n",
    "import keras.layers as L\n",
    "from keras import backend as K\n",
    "from utils import infer_length, infer_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ITranslationModel(object):\n",
    "\n",
    "    def make_initial_state(self, lines):\n",
    "        '''\n",
    "        Accepts array of lines.\n",
    "        Returns initial translation state for lines.\n",
    "        '''\n",
    "        raise Exception('Not implemented')\n",
    "    \n",
    "    def get_next_state_and_logits(self, state, outputs):\n",
    "        '''\n",
    "        Accepts current translation state and model outputs.\n",
    "        Returns next translation state and logits.\n",
    "        '''\n",
    "        raise Exception('Not implemented')\n",
    "    \n",
    "    def get_output_vocabulary(self):\n",
    "        '''\n",
    "        Return output vocabulary used in model.\n",
    "        '''\n",
    "        raise Exception('Not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharVocab(Vocab):\n",
    "    def __init__(self, chars, unk = '?'):\n",
    "        \"\"\"\n",
    "        A special class that converts lines of tokens into matrices and backwards\n",
    "        \"\"\"\n",
    "        assert unk not in chars\n",
    "        Vocab.__init__(self, tokens = chars + ['_BOS_', '_EOS_', unk], unk = unk)\n",
    "\n",
    "    def tokenize(self, string):\n",
    "        \"\"\"converts string to a list of tokens\"\"\"\n",
    "        tokens = [ch if ch in self.token_to_ix else self.unk\n",
    "                  for ch in string]\n",
    "        return [self.bos] + tokens + [self.eos]\n",
    "    \n",
    "    def tokenize_to_ids(self, string):\n",
    "        \n",
    "        token_ids = [self.token_to_ix.get(ch, self.unk_ix) for ch in string]\n",
    "        return [self.bos_ix] + token_ids + [self.eos_ix]\n",
    "\n",
    "    def to_lines(self, matrix, crop=True):\n",
    "        # input: matrix is numpy array of shape (n_lines, >=max_doc_len_in_char_tokens)\n",
    "        # return: list of string lines\n",
    "        lines = []\n",
    "        for line_ix in map(list,matrix):\n",
    "            if crop:\n",
    "                if line_ix[0] == self.bos_ix:\n",
    "                    line_ix = line_ix[1:]\n",
    "                if self.eos_ix in line_ix:\n",
    "                    line_ix = line_ix[:line_ix.index(self.eos_ix)]\n",
    "            line = ''.join(self.tokens[i] for i in line_ix)\n",
    "            lines.append(line)\n",
    "        return lines\n",
    "\n",
    "    def tok_matrix_to_char_matrix(self, tok_voc, tok_matrix, max_tok_len = 10):\n",
    "        # input: tok_matrix is numpy array of shape (n_lines, >=max_doc_len_in_bpe_tokens)\n",
    "        # input example for tok_voc.tokens = {101: 'a', 102: 'abc', 103: 'ca', ...}:\n",
    "        # [[101, 102]\n",
    "        #  [103, <eos>]]\n",
    "        # output_example for self.tokens = {1: 'a', 2: 'b', 3: 'c', ...}:\n",
    "        # [[[1, <eos>, <eos>], [1, 2, 3]]\n",
    "        #  [[3, 1, , <eos>], [<eos>, <eos>, <eos>]]]\n",
    "        assert tok_matrix.ndim == 2\n",
    "        \n",
    "        get_tok_str = lambda tok: tok_voc.tokens[tok].replace('@@', '@') if tok != tok_voc.eos_ix else ''\n",
    "        \n",
    "        max_len = max_tok_len or \\\n",
    "                  (max(map(lambda tok: len(get_tok_str(tok)), tok_matrix.flatten())) + 2)\n",
    "        assert max_len >= 2\n",
    "        \n",
    "        matrix = np.full(tok_matrix.shape + (max_len,),\n",
    "                         fill_value = self.eos_ix,\n",
    "                         dtype = np.int32)\n",
    "        \n",
    "        for i, tok_seq in enumerate(tok_matrix):\n",
    "            for j, tok in enumerate(tok_seq):\n",
    "                tok_str = get_tok_str(tok)[:max_len - 2]\n",
    "                matrix[i, j, :len(tok_str) + 2] = self.tokenize_to_ids(tok_str)\n",
    "\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_full_name(t):\n",
    "    assert isinstance(t, type)\n",
    "    res = t.__qualname__\n",
    "    if t.__module__ not in ('builtins', '__main__'):\n",
    "        res = t.__module__ + '.' + res\n",
    "    return res\n",
    "\n",
    "class ConfigBase(object):\n",
    "\n",
    "    def __init__(self, cfg, user_args, **kwargs):\n",
    "        # We need this class to avoid passing\n",
    "        # too many params in model classes initializers\n",
    "        # Example usage:\n",
    "        #    class MyConfig(ConfigBase):\n",
    "        #        def __init__(self, **kwargs):\n",
    "        #            super().__init__(self,\n",
    "        #                             user_args = kwargs,\n",
    "        #                             emb_size = None,\n",
    "        #                             hid_size = None,\n",
    "        #                             dropout_prob = None)\n",
    "        #\n",
    "        #    my_config = MyConfig(emb_size = 150,\n",
    "        #                         hid_size = 50,\n",
    "        #                         dropout_prob = 0)\n",
    "        \n",
    "        for key, user_val in user_args.items():\n",
    "            assert key in kwargs, 'Unknown field \"{}\" with value \"{}\"'.format(key, user_val)\n",
    "            assert user_val is not None, 'Field \"{}\" can\\'t have \"None\" value'.format(key)\n",
    "            \n",
    "            default_val = kwargs[key]\n",
    "            is_subconfig = isinstance(default_val, type) and issubclass(default_val, ConfigBase)\n",
    "            \n",
    "            if isinstance(user_val, ConfigBase):\n",
    "                assert is_subconfig, \\\n",
    "                       'Field \"{}\" is not a sub-config and can\\'t be set with config \"{}\"' \\\n",
    "                       .format(key, get_type_full_name(type(user_val)))\n",
    "                assert type(user_val) == default_val, \\\n",
    "                       'Sub-config \"{}\" must have type \"{}\", instead \"{}\" given' \\\n",
    "                       .format(key, get_type_full_name(default_val), get_type_full_name(type(user_val)))\n",
    "            elif is_subconfig:\n",
    "                assert isinstance(user_val, dict), \\\n",
    "                       'Sub-config \"{}\" of type \"{}\" can only be created from dict, not \"{}\" of type \"{}\"' \\\n",
    "                       .format(key, get_type_full_name(default_val), user_val, get_type_full_name(type(user_val)))\n",
    "                user_val = default_val(**user_val)\n",
    "            \n",
    "            kwargs[key] = user_val\n",
    "            \n",
    "        for key, user_val in kwargs.items():\n",
    "            assert user_val is not None, 'Field \"{}\" without default value is not set'.format(key)\n",
    "            setattr(cfg, key, user_val)\n",
    "        \n",
    "        self._keys = list(kwargs.keys())\n",
    "    \n",
    "    def as_dict(self):\n",
    "        res = {key: getattr(self, key) for key in self._keys}\n",
    "        for key in self._keys:\n",
    "            if isinstance(res[key], ConfigBase):\n",
    "                res[key] = res[key].as_dict()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scope_trainable_variables(sub_scope_name = None):\n",
    "    full_scope_name = tf.get_variable_scope().name\n",
    "    if full_scope_name != '':\n",
    "        full_scope_name += '/'\n",
    "    if sub_scope_name is not None:\n",
    "        full_scope_name += sub_scope_name + '/'\n",
    "    return tf.trainable_variables(scope = re.escape(full_scope_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.layers as L\n",
    "from keras import backend as K\n",
    "from utils import infer_length, infer_mask\n",
    "\n",
    "\n",
    "class AttentionLayer:\n",
    "    \n",
    "    def __init__(self, name, hid_size, activ=tf.tanh):\n",
    "        \"\"\" A layer that computes additive attention response and weights \"\"\"\n",
    "        self.name = name\n",
    "        self.hid_size = hid_size # attention layer hidden units\n",
    "        self.activ = activ       # attention layer hidden nonlinearity\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            # YOUR CODE - create layer variables\n",
    "            #<YOUR CODE>\n",
    "            self.linear_e = L.Dense(hid_size)\n",
    "            self.linear_d = L.Dense(hid_size)\n",
    "            self.linear_out = L.Dense(1)\n",
    "\n",
    "    def __call__(self, enc, dec, inp_mask):\n",
    "        \"\"\"\n",
    "        Computes attention response and weights\n",
    "        :param enc: encoder activation sequence, float32[batch_size, ninp, enc_size]\n",
    "        :param dec: single decoder state used as \"query\", float32[batch_size, dec_size]\n",
    "        :param inp_mask: mask on enc activatons (0 after first eos), float32 [batch_size, ninp]\n",
    "        :returns: attn[batch_size, enc_size], probs[batch_size, ninp]\n",
    "            - attn - attention response vector (weighted sum of enc)\n",
    "            - probs - attention weights after softmax\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(self.name):\n",
    "            \n",
    "            # Compute logits\n",
    "            #<...>\n",
    "            logits_seq = self.linear_out(self.activ(self.linear_e(enc) + \\\n",
    "                                                    self.linear_d(dec)[:, tf.newaxis, :]))\n",
    "            logits_seq = tf.squeeze(logits_seq, axis = -1)\n",
    "            \n",
    "            # Apply mask - if mask is 0, logits should be -inf or -1e9\n",
    "            # You may need tf.where\n",
    "            #<...>\n",
    "            \n",
    "            logits_seq = tf.where(inp_mask, logits_seq, tf.fill(tf.shape(logits_seq),\n",
    "                                                                -np.inf))\n",
    "            \n",
    "            # Compute attention probabilities (softmax)\n",
    "            probs = tf.nn.softmax(logits_seq) # <...>\n",
    "            \n",
    "            # Compute attention response using enc and probs\n",
    "            attn = tf.reduce_sum(probs[..., tf.newaxis] * enc, axis = 1) # <...>\n",
    "            \n",
    "            return attn, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuCharEncoder:\n",
    "    # This class is needed to create chr representation,\n",
    "    # which is, like in DeepSpeare,\n",
    "    # shareable between translator and meter models\n",
    "    \n",
    "    class Config(ConfigBase):\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(self,\n",
    "                             kwargs,\n",
    "                             emb_size = None,\n",
    "                             hid_size = None,\n",
    "                             dropout_prob = None)\n",
    "    \n",
    "    deepspeare_en_config = Config(emb_size = 150,  # as 'char_embedding_dim'\n",
    "                                  hid_size = 50,   # as 'pm_enc_dim'\n",
    "                                  #dropout_prob = 1 - 0.7) # as 'keep_prob'\n",
    "                                  dropout_prob = 0) # to show proper BLEU\n",
    "    \n",
    "    def __init__(self, name, config, is_training):\n",
    "        # ToDo: deal with 'is_training'\n",
    "        \n",
    "        assert type(name) == str\n",
    "        assert type(config) == RuCharEncoder.Config\n",
    "\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "        \n",
    "        ru_vowels = ['а', 'е', 'ё', 'и', 'о', 'у', 'ы', 'э', 'ю', 'я']\n",
    "        ru_other_letters = [chr(n) for n in range(ord('а'), ord('я') + 1) if chr(n) not in ru_vowels]\n",
    "        vocab = CharVocab(chars = ru_vowels + ru_other_letters + [' ', '@'])\n",
    "        self.space_idx = vocab.token_to_ix[' ']\n",
    "        self.tok_concat_idx = vocab.token_to_ix['@']\n",
    "        self._vowel_max_idx = len(ru_vowels) - 1\n",
    "        self._ru_char_voc = vocab\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            self._inp = tf.placeholder(tf.int32, [None, None])\n",
    "            \n",
    "            self._emb_inp = L.Embedding(len(self._ru_char_voc), config.emb_size)\n",
    "            \n",
    "            # In original DeepSpeare code they use the same LSTM Cell\n",
    "            # for both directions\n",
    "            # Maybe it's better to use two separate cells:\n",
    "            #self._enc_lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(config.hid_size)\n",
    "            #self._enc_lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(config.hid_size)\n",
    "            \n",
    "            enc_cell = tf.nn.rnn_cell.LSTMCell(config.hid_size)\n",
    "            if is_training and config.dropout_prob > 0:\n",
    "                enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob = 1 - config.dropout_prob)\n",
    "                \n",
    "            self._enc_lstm_fw_cell = enc_cell\n",
    "            self._enc_lstm_bw_cell = enc_cell\n",
    "            \n",
    "            self._enc_seq, self._en_last_hid = self.encode(self._inp)\n",
    "            \n",
    "            self.trainable_variables = get_scope_trainable_variables()\n",
    "\n",
    "    def lines_to_char_matrix(self, lines, max_len = 100):\n",
    "        return self._ru_char_voc.to_matrix(lines, max_len)\n",
    "            \n",
    "    def tok_matrix_to_char_matrix(self, tok_voc, tok_matrix, max_tok_len = 10):\n",
    "        return self._ru_char_voc.tok_matrix_to_char_matrix(tok_voc, tok_matrix, max_tok_len)\n",
    "            \n",
    "    def vowel_mask(self, inp):\n",
    "        return inp <= self._vowel_max_idx\n",
    "    \n",
    "    def make_input_feed_dict(self, inp_lines):\n",
    "        return { self._inp: self._ru_char_voc.to_matrix(inp_lines) }\n",
    "    \n",
    "    def get_input(self):\n",
    "        return self._inp\n",
    "    \n",
    "    def get_eos_ix(self):\n",
    "        return self._ru_char_voc.eos_ix\n",
    "    \n",
    "    def get_encoded_seq(self):\n",
    "        return self._enc_seq\n",
    "    \n",
    "    def get_encoded_last_hid(self):\n",
    "        return self._en_last_hid\n",
    "    \n",
    "    def encode(self, inp):\n",
    "        '''\n",
    "        Return tuple:\n",
    "        res[0]: encode seq, float32[batch_size, max_time, cfg.hid_size * 2]\n",
    "        res[1]: encode last hidden state, float32[batch_size, cfg.hid_size * 2]\n",
    "        '''\n",
    "        assert inp.shape.ndims == 2 # [batch_size, max_time]\n",
    "        \n",
    "        inp_lengths = infer_length(inp, self._ru_char_voc.eos_ix)\n",
    "        \n",
    "        inp_emb = self._emb_inp(inp)\n",
    "        with tf.variable_scope('enc'):\n",
    "            ((enc_seq_fw,\n",
    "              enc_seq_bw),\n",
    "             (enc_last_fw,\n",
    "              enc_last_bw)) = tf.nn.bidirectional_dynamic_rnn(self._enc_lstm_fw_cell,\n",
    "                                                              self._enc_lstm_bw_cell,\n",
    "                                                              inp_emb,\n",
    "                                                              sequence_length = inp_lengths,\n",
    "                                                              dtype = inp_emb.dtype)\n",
    "        enc_seq = tf.concat((enc_seq_fw, enc_seq_bw), axis = -1)\n",
    "        enc_last_hid = tf.concat((enc_last_fw[1], enc_last_bw[1]), axis = -1)\n",
    "        return enc_seq, enc_last_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_length_exclude_eos(seq, eos_ix, dtype=tf.int32):\n",
    "    is_eos = tf.cast(tf.equal(seq, eos_ix), dtype)\n",
    "    count_eos = tf.cumsum(is_eos,axis=1,exclusive=False)\n",
    "    lengths = tf.reduce_sum(tf.cast(tf.equal(count_eos,0),dtype),axis=1)\n",
    "    return lengths\n",
    "\n",
    "class MeterModel:\n",
    "    # Neural architecture of meter model\n",
    "    # and most of code\n",
    "    # are borrowed from DeepSpeare Pentameter model\n",
    "\n",
    "    class Config(ConfigBase):\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(self,\n",
    "                             kwargs,\n",
    "                             max_out_length = None,\n",
    "                             # From deepspeare code:\n",
    "                             dropout_prob = None,\n",
    "                             pm_dec_dim = None,\n",
    "                             max_grad_norm = None,\n",
    "                             pm_learning_rate = None,\n",
    "                             pm_attend_dim = None,\n",
    "                             sigma = None,\n",
    "                             cov_loss_threshold = None,\n",
    "                             repeat_loss_scale = None,\n",
    "                             cov_loss_scale = None)\n",
    "            \n",
    "    deepspeare_config = Config(max_out_length = 15,\n",
    "                               # From deepspeare code:\n",
    "                               #dropout_prob = 1 - 0.7, # as 'keep_prob'\n",
    "                               dropout_prob = 0, # to show proper BLEU\n",
    "                               pm_dec_dim=200,\n",
    "                               pm_attend_dim=50,\n",
    "                               pm_learning_rate=0.001,\n",
    "                               repeat_loss_scale=1.0,\n",
    "                               cov_loss_scale=1.0,\n",
    "                               cov_loss_threshold=0.7,\n",
    "                               sigma=1.00,\n",
    "                               max_grad_norm=5)\n",
    "    \n",
    "    def __init__(self, name, config, batch_size, is_training, ru_char_encoder):\n",
    "        \n",
    "        assert type(name) == str\n",
    "        assert type(config) == MeterModel.Config\n",
    "\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "\n",
    "        self._ru_char_encoder = ru_char_encoder\n",
    "        self._stress_eos_ix = -1\n",
    "\n",
    "        cfg = self.config\n",
    "        cfg_pm_enc_dim = ru_char_encoder.config.hid_size\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            self._out = tf.placeholder(tf.int32, [None, None])\n",
    "\n",
    "            dec_cell = tf.nn.rnn_cell.LSTMCell(cfg.pm_dec_dim)\n",
    "            #if is_training and cfg.dropout_prob > 0:\n",
    "            #    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob = 1 - cfg.dropout_prob)\n",
    "\n",
    "            enc_hiddens = ru_char_encoder.get_encoded_seq()\n",
    "            enc_hiddens  = tf.reshape(enc_hiddens, [-1, cfg_pm_enc_dim*2]) #[batch_size*num_steps, hidden]\n",
    "                    \n",
    "            #if not is_training:\n",
    "            self.pm_costs     = self.compute_pm_loss(batch_size = batch_size,\n",
    "                                                     enc_hiddens = enc_hiddens,\n",
    "                                                     dec_cell = dec_cell)\n",
    "            self.pm_mean_cost = tf.reduce_sum(self.pm_costs) / batch_size\n",
    "            \n",
    "            self.trainable_variables = get_scope_trainable_variables() + \\\n",
    "                                       ru_char_encoder.trainable_variables\n",
    "\n",
    "        if is_training:\n",
    "            #run optimiser and backpropagate (clipped) gradients for pm loss\n",
    "            pm_tvars         = self.trainable_variables\n",
    "            pm_grads, _      = tf.clip_by_global_norm(tf.gradients(self.pm_mean_cost, pm_tvars),\n",
    "                                                      cfg.max_grad_norm)\n",
    "            self.pm_train_op = tf.train.AdamOptimizer(cfg.pm_learning_rate).apply_gradients(zip(pm_grads, pm_tvars))\n",
    "    \n",
    "    def get_input(self):\n",
    "        return self._ru_char_encoder.get_input()\n",
    "    \n",
    "    def get_output(self):\n",
    "        return self._out\n",
    "    \n",
    "    def to_stress_matrix(self, stress_lines):\n",
    "        \n",
    "        max_len = min(self.config.max_out_length, max(map(len, stress_lines)))\n",
    "\n",
    "        matrix = np.full((len(stress_lines), max_len), fill_value = self._stress_eos_ix, dtype = np.int32)\n",
    "        for i, stresses in enumerate(stress_lines):\n",
    "            stresses = stresses[:max_len]\n",
    "            matrix[i, :len(stresses)] = stresses\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    # -- compute pentameter model loss, given a pentameter input\n",
    "    # It may seem strange that we pass dec_cell here despite it is \n",
    "    def compute_pm_loss(self, batch_size, enc_hiddens, dec_cell):\n",
    "        \n",
    "        # Note: Deepspeare uses old TensorFlow API where tf.concat accepts axis first like: tf.concat(1, [t1, t2])\n",
    "        # So, here it is changed to new TF style: tf.concat([t1, t2], axis = 1)\n",
    "\n",
    "        cfg = self.config\n",
    "        cfg_pm_enc_dim = self._ru_char_encoder.config.hid_size\n",
    "\n",
    "        space_id = self._ru_char_encoder.space_idx\n",
    "\n",
    "        inp = self.get_input()\n",
    "        out = self.get_output()\n",
    "        out_len = infer_length_exclude_eos(out, self._stress_eos_ix)\n",
    "        max_out_len = tf.shape(out)[1]\n",
    "\n",
    "        eos_ix = self._ru_char_encoder.get_eos_ix()\n",
    "        inp_lengths = infer_length(inp, eos_ix)\n",
    "        inp_mask = infer_mask(inp, eos_ix, dtype = tf.bool)\n",
    "        pm_cov_mask = tf.cast(self._ru_char_encoder.vowel_mask(inp) & inp_mask, dtype = tf.float32)\n",
    "        #xlen_max       = tf.reduce_max(inp_lengths) # Logic in Deepspeare\n",
    "        xlen_max       = tf.shape(inp)[1] # Our current logic\n",
    "\n",
    "        #use decoder hidden states to select encoder hidden states to predict stress for next time step\n",
    "        repeat_loss    = tf.zeros([batch_size])\n",
    "        attentions     = tf.zeros([batch_size, xlen_max]) #historical attention weights\n",
    "        prev_miu       = tf.zeros([batch_size,1])\n",
    "        outputs        = []\n",
    "        attention_list = []\n",
    "        miu_list       = []\n",
    "\n",
    "        #initial inputs (learnable) and state\n",
    "        initial_inputs = tf.get_variable(\"dec_init_input\", [cfg_pm_enc_dim*2])\n",
    "        inputs         = tf.reshape(tf.tile(initial_inputs, [batch_size]), [batch_size, -1])\n",
    "        state          = dec_cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        #manual unroll of time steps because attention depends on previous attention weights\n",
    "        with tf.variable_scope(\"RNN\"):\n",
    "            for time_step in range(cfg.max_out_length):\n",
    "\n",
    "                if time_step > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                def attend(enc_hiddens, dec_hidden, attn_hist, prev_miu):\n",
    "                    with tf.variable_scope(\"pm_attention\"):\n",
    "                        attend_w = tf.get_variable(\"attend_w\", [cfg_pm_enc_dim*2+cfg.pm_dec_dim, cfg.pm_attend_dim])\n",
    "                        attend_b = tf.get_variable(\"attend_b\", [cfg.pm_attend_dim], initializer=tf.constant_initializer())\n",
    "                        attend_v = tf.get_variable(\"attend_v\", [cfg.pm_attend_dim, 1])\n",
    "                        miu_w    = tf.get_variable(\"miu_w\", [cfg.pm_dec_dim+1, cfg.pm_attend_dim])\n",
    "                        miu_b    = tf.get_variable(\"miu_b\", [cfg.pm_attend_dim], initializer=tf.constant_initializer())\n",
    "                        miu_v    = tf.get_variable(\"miu_v\", [cfg.pm_attend_dim, 1])\n",
    "\n",
    "                    #position attention\n",
    "                    miu     = tf.minimum(tf.sigmoid(tf.matmul(tf.tanh(tf.matmul(tf.concat(\n",
    "                        [dec_hidden, prev_miu], axis = 1), miu_w) + miu_b), miu_v)) + prev_miu, tf.ones([batch_size, 1]))\n",
    "                    miu_p   = miu * tf.reshape(tf.cast(inp_lengths-1, tf.float32), [-1, 1])\n",
    "                    pos     = tf.cast(tf.reshape(tf.tile(tf.range(xlen_max), [batch_size]), [batch_size, -1]),\n",
    "                        dtype=tf.float32)\n",
    "                    pos_lp  = -(pos - miu_p)**2 / (2 * tf.reshape(tf.tile([tf.square(cfg.sigma)], [batch_size]),\n",
    "                        [batch_size,-1]))\n",
    "\n",
    "                    #char encoding attention\n",
    "                    pos_weight = tf.reshape(tf.exp(pos_lp), [-1, 1])\n",
    "                    inp_concat = tf.concat([enc_hiddens * pos_weight,\n",
    "                        tf.reshape(tf.tile(dec_hidden, [1,xlen_max]), [-1,cfg.pm_dec_dim])], axis = 1)\n",
    "                    x       = inp\n",
    "                    e       = tf.matmul(tf.tanh(tf.matmul(inp_concat, attend_w) + attend_b), attend_v)\n",
    "                    e       = tf.reshape(e, [batch_size, xlen_max])\n",
    "                    mask1   = tf.cast(~inp_mask, dtype=tf.float32)\n",
    "                    mask2   = tf.cast(tf.equal(x, tf.fill(tf.shape(x), space_id)), dtype=tf.float32)\n",
    "                    e_mask  = tf.maximum(mask1, mask2)\n",
    "                    e_mask *= tf.constant(-1e20)\n",
    "\n",
    "                    #combine alpha with position probability\n",
    "                    alpha   = tf.nn.softmax(e + e_mask + pos_lp)\n",
    "                    #alpha   = tf.nn.softmax(e + e_mask)\n",
    "\n",
    "                    #weighted sum\n",
    "                    c       = tf.reduce_sum(tf.expand_dims(alpha, 2)*tf.reshape(enc_hiddens,\n",
    "                        [batch_size, xlen_max, cfg_pm_enc_dim*2]), 1)\n",
    "\n",
    "                    return c, alpha, miu\n",
    "\n",
    "                dec_hidden, state               = dec_cell(inputs, state)\n",
    "                enc_hiddens_sum, attn, prev_miu = attend(enc_hiddens, dec_hidden, attentions, prev_miu)\n",
    "\n",
    "                # Zero 'attn' if past end of output:\n",
    "                valid_step = time_step < out_len\n",
    "                attn *= tf.cast(valid_step, tf.float32)[:, tf.newaxis]\n",
    "                \n",
    "                repeat_loss += tf.reduce_sum(tf.minimum(attentions, attn), 1)\n",
    "                attentions  += attn\n",
    "                inputs       = enc_hiddens_sum\n",
    "\n",
    "                attention_list.append(attn)\n",
    "                miu_list.append(prev_miu)\n",
    "                outputs.append(enc_hiddens_sum)\n",
    "\n",
    "        #reshape output into [batch_size*num_steps,hidden_size]\n",
    "        #outputs = tf.reshape(tf.concat(outputs, axis = 1), [-1, cfg_pm_enc_dim*2]) # Original code\n",
    "        outputs = tf.concat(outputs, axis = 1)\n",
    "        outputs = outputs[:, :max_out_len * cfg_pm_enc_dim*2] # Also truncate outputs\n",
    "        outputs = tf.reshape(outputs, [-1, cfg_pm_enc_dim*2])\n",
    "        \n",
    "\n",
    "        #compute loss\n",
    "        pm_softmax_w = tf.get_variable(\"pm_softmax_w\", [cfg_pm_enc_dim*2, 1])\n",
    "        pm_softmax_b = tf.get_variable(\"pm_softmax_b\", [1], initializer=tf.constant_initializer())\n",
    "        pm_logit     = tf.squeeze(tf.matmul(outputs, pm_softmax_w) + pm_softmax_b)\n",
    "        pm_crossent  = tf.nn.sigmoid_cross_entropy_with_logits(logits = pm_logit,\n",
    "            #labels = tf.tile(tf.cast(fixed_out, tf.float32), [batch_size])) # Original code\n",
    "            labels = tf.reshape(tf.cast(out, tf.float32), [-1]))\n",
    "        cov_loss     = tf.reduce_sum(tf.nn.relu(pm_cov_mask*cfg.cov_loss_threshold - attentions), 1)\n",
    "        pm_cost      = tf.reduce_sum(tf.reshape(pm_crossent, [batch_size, -1]), 1) + \\\n",
    "            cfg.repeat_loss_scale*repeat_loss + cfg.cov_loss_scale*cov_loss\n",
    "\n",
    "        #save some variables\n",
    "        self.pm_logits     = tf.sigmoid(tf.reshape(pm_logit, [batch_size, -1]))\n",
    "        self.pm_attentions = attention_list\n",
    "        self.mius          = miu_list\n",
    "\n",
    "        return pm_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveModel(ITranslationModel):\n",
    "    \n",
    "    class Config(ConfigBase):\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(self,\n",
    "                             kwargs,\n",
    "                             batch_size = None,\n",
    "                             emb_size = None,\n",
    "                             hid_size = None,\n",
    "                             #attn_size = None,\n",
    "                             ru_char_encoder_config = RuCharEncoder.Config,\n",
    "                             meter_config = MeterModel.Config)\n",
    "    \n",
    "    def __init__(self, sess, filename, name = None, inp_voc = None, out_voc = None, config = None):\n",
    "        \n",
    "        self.sess = sess\n",
    "        \n",
    "        if filename is None:\n",
    "            self.initialize(name, inp_voc, out_voc, config)\n",
    "        else:\n",
    "            self.load(filename)\n",
    "    \n",
    "    \n",
    "    def initialize(self, name, inp_voc, out_voc, config):\n",
    "        \n",
    "        assert type(config) == AttentiveModel.Config\n",
    "        \n",
    "        self.name = name\n",
    "        self.inp_voc = inp_voc\n",
    "        self.out_voc = out_voc\n",
    "        self.config = config\n",
    "        cfg = config\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            # YOUR CODE - define model layers\n",
    "            \n",
    "            # <...>\n",
    "            self.emb_inp = L.Embedding(len(inp_voc), cfg.emb_size)\n",
    "            self.emb_out = L.Embedding(len(out_voc), cfg.emb_size)\n",
    "            self.enc_lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(cfg.hid_size)\n",
    "            self.enc_lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(cfg.hid_size)\n",
    "            #self.enc0 = tf.nn.rnn_cell.GRUCell(cfg.hid_size)\n",
    "\n",
    "            self.dec_start = L.Dense(cfg.hid_size)\n",
    "            self.dec0 = tf.nn.rnn_cell.GRUCell(cfg.hid_size)\n",
    "            self.dense = L.Dense(cfg.hid_size)\n",
    "            self.activ = tf.tanh\n",
    "            self.logits = L.Dense(len(out_voc))\n",
    "            \n",
    "            self.attention = AttentionLayer(name = 'attention',\n",
    "                                            hid_size = 2 * cfg.hid_size)\n",
    "            \n",
    "            self._ru_char_encoder = RuCharEncoder(name = 'ru_char_encoder',\n",
    "                                                  config = cfg.ru_char_encoder_config,\n",
    "                                                  is_training = True)\n",
    "            \n",
    "            self.meter_model = MeterModel(name = 'meter',\n",
    "                                          config = cfg.meter_config,\n",
    "                                          batch_size = cfg.batch_size,\n",
    "                                          is_training = True,\n",
    "                                          ru_char_encoder = self._ru_char_encoder)\n",
    "            \n",
    "            # END OF YOUR CODE\n",
    "            \n",
    "            # prepare to translate_lines\n",
    "            self.inp = tf.placeholder('int32', [None, None])\n",
    "            self.initial_state = self.prev_state = self.encode(self.inp)\n",
    "            self.prev_tokens = tf.placeholder('int32', [None])\n",
    "            self.prev_char_tokens = tf.placeholder('int32', [None, None])\n",
    "            self.next_state, self.next_logits = self.decode(self.prev_state, self.prev_tokens, self.prev_char_tokens)\n",
    "            self.next_softmax = tf.nn.softmax(self.next_logits)\n",
    "\n",
    "            self.trainable_variables = get_scope_trainable_variables()\n",
    "        \n",
    "        # Call to 'K.get_session()' runs variable initializes for\n",
    "        # all variables including ones initialized using\n",
    "        # 'tf.global_variables_initializer()' (at least for Keras\n",
    "        # 2.0.5) thus it have to be called once here or model weights\n",
    "        # will be rewritten after training e.g. when 'get_weights' is\n",
    "        # called.\n",
    "        K.get_session()\n",
    "    \n",
    "    def to_out_char_matrix(self, out_tok_matrix, max_tok_len = 10):\n",
    "        return self._ru_char_encoder.tok_matrix_to_char_matrix(self.out_voc, out_tok_matrix, max_tok_len)\n",
    "    \n",
    "    def to_meter_inp_char_matrix(self, inp_lines, max_len = 100):\n",
    "        return self._ru_char_encoder.lines_to_char_matrix(inp_lines, max_len)\n",
    "    \n",
    "    def to_meter_out_stress_matrix(self, stress_lines):\n",
    "        return self.meter_model.to_stress_matrix(stress_lines)\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Takes symbolic input sequence, computes initial state\n",
    "        :param inp: matrix of input tokens [batch, time]\n",
    "        :return: a list of initial decoder state tensors\n",
    "        \"\"\"\n",
    "        \n",
    "        # encode input sequence, create initial decoder states\n",
    "        # <YOUR CODE>\n",
    "        inp_lengths = infer_length(inp, self.inp_voc.eos_ix)\n",
    "        inp_mask = infer_mask(inp, self.inp_voc.eos_ix, dtype = tf.bool)\n",
    "        \n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        with tf.variable_scope('enc0'):\n",
    "            #enc_seq, enc_last = tf.nn.dynamic_rnn(self.enc0,\n",
    "            #                                      inp_emb,\n",
    "            #                                      sequence_length = inp_lengths,\n",
    "            #                                      dtype = inp_emb.dtype)\n",
    "            ((enc_seq_fw,\n",
    "              enc_seq_bw),\n",
    "             ((enc_last_fw_cell_state,\n",
    "               enc_last_fw_hid_state),\n",
    "              enc_last_bw_state_tuple)) = tf.nn.bidirectional_dynamic_rnn(self.enc_lstm_fw_cell,\n",
    "                                                                          self.enc_lstm_bw_cell,\n",
    "                                                                          inp_emb,\n",
    "                                                                          sequence_length = inp_lengths,\n",
    "                                                                          dtype = inp_emb.dtype)\n",
    "        enc_seq = tf.concat((enc_seq_fw, enc_seq_bw), axis = -1)\n",
    "        # TODO: Don't feed cell LSTM state to decoder\n",
    "        enc_last_fw = tf.concat([enc_last_fw_cell_state,\n",
    "                                 enc_last_fw_hid_state], axis = 1)\n",
    "        dec_start = self.dec_start(enc_last_fw)\n",
    "        \n",
    "        # apply attention layer from initial decoder hidden state\n",
    "        #first_attn_probas = <...>\n",
    "        _, first_attn_probas = self.attention(enc_seq, dec_start, inp_mask)\n",
    "        \n",
    "        # Build first state: include\n",
    "        # * initial states for decoder recurrent layers\n",
    "        # * encoder sequence and encoder attn mask (for attention)\n",
    "        # * make sure that last state item is attention probabilities tensor\n",
    "        \n",
    "        #first_state = [<...>, first_attn_probas]\n",
    "        first_state = [dec_start, enc_seq, inp_mask, first_attn_probas]\n",
    "        return first_state\n",
    "\n",
    "    def decode(self, prev_state, prev_tokens, prev_char_tokens):\n",
    "        \"\"\"\n",
    "        Takes previous decoder state and tokens, returns new state and logits\n",
    "        :param prev_state: a list of previous decoder state tensors\n",
    "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
    "        :param prev_char_tokens: previous output tokens, an int vector of [batch_size, max_tok_len_in_chars]\n",
    "        :return: a list of next decoder state tensors, a tensor of logits [batch,n_tokens]\n",
    "        \"\"\"\n",
    "        # Unpack your state: you will get tensors in the same order\n",
    "        # that you've packed in encode\n",
    "        #[<...>, prev_attn_probas] = prev_state\n",
    "        [prev_dec, enc_seq, inp_mask, prev_attn_probas] = prev_state\n",
    "        \n",
    "        \n",
    "        # Perform decoder step\n",
    "        # * predict next attn response and attn probas given previous decoder state\n",
    "        # * use prev token embedding and attn response to update decoder states\n",
    "        # * (concatenate and feed into decoder cell)\n",
    "        # * predict logits\n",
    "        \n",
    "        # <APPLY_ATTENTION>\n",
    "        next_attn_response, next_attn_probas = self.attention(enc_seq, prev_dec, inp_mask)\n",
    "\n",
    "        # <YOUR CODE>\n",
    "        prev_emb = self.emb_out(prev_tokens[:, tf.newaxis])[:,0]\n",
    "        \n",
    "        _, prev_char_hid = self._ru_char_encoder.encode(prev_char_tokens)\n",
    "        \n",
    "        dec_inputs = tf.concat([prev_emb, prev_char_hid, next_attn_response], axis = 1)\n",
    "        with tf.variable_scope('dec0'):\n",
    "            new_dec_out, new_dec_state = self.dec0(dec_inputs, prev_dec)\n",
    "        output_logits = self.logits(self.activ(self.dense(new_dec_out)))\n",
    "        #output_logits = self.logits(self.activ(new_dec_out))\n",
    "        \n",
    "        # Pack new state:\n",
    "        # * replace previous decoder state with next one\n",
    "        # * copy encoder sequence and mask from prev_state\n",
    "        # * append new attention probas\n",
    "        #next_state = [<...>, next_attn_probas]\n",
    "        next_state = [new_dec_state, enc_seq, inp_mask, next_attn_probas]\n",
    "        return next_state, output_logits\n",
    "\n",
    "    \n",
    "    def compute_logits(self, inp, out, out_char):\n",
    "        \n",
    "        batch_size = tf.shape(inp)[0]\n",
    "\n",
    "        # Encode inp, get initial state\n",
    "        first_state = self.encode(inp) # <YOUR CODE HERE>\n",
    "\n",
    "        # initial logits: always predict BOS\n",
    "        first_logits = tf.log(tf.one_hot(tf.fill([batch_size], self.out_voc.bos_ix),\n",
    "                                         len(self.out_voc)) + 1e-30)\n",
    "\n",
    "        # Decode step\n",
    "        def step(prev_state, y_prev, y_char_prev):\n",
    "            # Given previous state, obtain next state and next token logits\n",
    "            # <YOUR CODE>\n",
    "            next_dec_state, next_logits = self.decode(prev_state, y_prev, y_char_prev)\n",
    "            return next_dec_state, next_logits # <...>\n",
    "\n",
    "        # You can now use tf.scan to run step several times.\n",
    "        # use tf.transpose(out) as elems (to process one time-step at a time)\n",
    "        # docs: https://www.tensorflow.org/api_docs/python/tf/scan\n",
    "\n",
    "        # <YOUR CODE>\n",
    "\n",
    "        out = tf.scan(lambda a, y: step(a[0], y[0], y[1]),\n",
    "                      elems = (tf.transpose(out)[:-1], tf.transpose(out_char, [1, 0, 2])[:-1]),\n",
    "                      initializer = (first_state, first_logits))\n",
    "\n",
    "\n",
    "        # FIXME remove?\n",
    "        #self.sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        logits_seq = out[1] # <YOUR CODE>\n",
    "\n",
    "        # prepend first_logits to logits_seq\n",
    "        logits_seq = tf.concat((first_logits[tf.newaxis], logits_seq), axis = 0) #<...>\n",
    "\n",
    "        # Make sure you convert logits_seq from\n",
    "        # [time, batch, voc_size] to [batch, time, voc_size]\n",
    "        logits_seq = tf.transpose(logits_seq, perm = [1, 0, 2]) #<...>\n",
    "\n",
    "        return logits_seq\n",
    "\n",
    "    def compute_loss(self, inp, out, out_char):\n",
    "        \n",
    "        mask = infer_mask(out, out_voc.eos_ix)    \n",
    "        logits_seq = self.compute_logits(inp, out, out_char)\n",
    "\n",
    "        # Compute loss as per instructions above\n",
    "        # <YOUR CODE>\n",
    "\n",
    "        prob_seq = tf.nn.softmax(logits_seq)\n",
    "        out_one_hot = tf.one_hot(out, len(self.out_voc))\n",
    "\n",
    "        prob_seq_masked = tf.boolean_mask(prob_seq, mask)\n",
    "        out_one_hot_masked = tf.boolean_mask(out_one_hot, mask)\n",
    "        prob_seq_out = tf.boolean_mask(prob_seq_masked, out_one_hot_masked)\n",
    "        loss = tf.reduce_mean(-tf.log(prob_seq_out))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def make_initial_state(self, inp_lines):\n",
    "        return self.sess.run(self.initial_state, {self.inp: self.inp_voc.to_matrix(inp_lines)})\n",
    "    \n",
    "    def get_next_state_and_logits(self, state, outputs):\n",
    "        \n",
    "        if type(outputs) == list:\n",
    "            prev_tokens = np.array([out[-1] for out in outputs], dtype = np.int32)\n",
    "        else:\n",
    "            prev_tokens = outputs[:, -1]\n",
    "        prev_char_tokens = np.squeeze(self.to_out_char_matrix(prev_tokens[:, np.newaxis]), axis = 1)\n",
    "        \n",
    "        return self.sess.run([self.next_state, self.next_logits],\n",
    "                             {**dict(zip(self.prev_state, state)),\n",
    "                              self.prev_tokens: prev_tokens,\n",
    "                              self.prev_char_tokens: prev_char_tokens})\n",
    "                         \n",
    "    def get_output_vocabulary(self):\n",
    "        return self.out_voc\n",
    "    \n",
    "    \n",
    "    def translate_lines(self, inp_lines, max_len=100):\n",
    "        \"\"\"\n",
    "        Translates a list of lines by greedily selecting most likely next token at each step\n",
    "        :returns: a list of output lines, a sequence of model states at each step\n",
    "        \"\"\"\n",
    "        state = self.make_initial_state(inp_lines)\n",
    "        outputs = [[self.out_voc.bos_ix] for _ in range(len(inp_lines))]\n",
    "        all_states = [state]\n",
    "        finished = [False] * len(inp_lines)\n",
    "\n",
    "        for t in range(max_len):\n",
    "            state, logits = self.get_next_state_and_logits(state, outputs)\n",
    "            next_tokens = np.argmax(logits, axis=-1)\n",
    "            all_states.append(state)\n",
    "            for i in range(len(next_tokens)):\n",
    "                outputs[i].append(next_tokens[i])\n",
    "                finished[i] |= next_tokens[i] == self.out_voc.eos_ix\n",
    "        return self.out_voc.to_lines(outputs), all_states\n",
    "    \n",
    "    def dump(self, filename):\n",
    "        \n",
    "        assert False, 'Not implemented yet'\n",
    "        values = {'name': self.name,\n",
    "                  'config': self.config.as_dict(),\n",
    "                  'inp_voc': self.inp_voc,\n",
    "                  'out_voc': self.out_voc,\n",
    "                  'emb_inp_weights': self.emb_inp.get_weights(),\n",
    "                  'emb_out_weights': self.emb_out.get_weights(),\n",
    "                  #'enc0_weights': self.enc0.get_weights(),\n",
    "                  'enc_lstm_fw_cell_weights': self.enc_lstm_fw_cell.get_weights(),\n",
    "                  'enc_lstm_bw_cell_weights': self.enc_lstm_bw_cell.get_weights(),\n",
    "                  'dec0_weights': self.dec0.get_weights(),\n",
    "                  'dec_start_weights': self.dec_start.get_weights(),\n",
    "                  'dense_weights': self.dense.get_weights(),\n",
    "                  'logits_weights': self.logits.get_weights(),\n",
    "                  'attn__linear_e_weights': self.attention.linear_e.get_weights(),\n",
    "                  'attn__linear_d_weights': self.attention.linear_d.get_weights(),\n",
    "                  'attn__linear_out_weights': self.attention.linear_out.get_weights()}\n",
    "        pickle.dump(values, open(filename, 'wb'))\n",
    "    \n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            values = pickle.load(f)\n",
    "        self.initialize(values['name'], values['inp_voc'], values['out_voc'],\n",
    "                        AttentiveModel.Config(**values['config']))\n",
    "        self.emb_inp.set_weights(values['emb_inp_weights'])\n",
    "        self.emb_out.set_weights(values['emb_out_weights'])\n",
    "        #self.enc0.set_weights(values['enc0_weights'])\n",
    "        self.enc_lstm_fw_cell.set_weights(values['enc_lstm_fw_cell_weights'])\n",
    "        self.enc_lstm_bw_cell.set_weights(values['enc_lstm_bw_cell_weights'])\n",
    "        self.dec0.set_weights(values['dec0_weights'])\n",
    "        self.dec_start.set_weights(values['dec_start_weights'])\n",
    "        self.dense.set_weights(values['dense_weights'])\n",
    "        self.logits.set_weights(values['logits_weights'])\n",
    "        self.attention.linear_e.set_weights(values['attn__linear_e_weights'])\n",
    "        self.attention.linear_d.set_weights(values['attn__linear_d_weights'])\n",
    "        self.attention.linear_out.set_weights(values['attn__linear_out_weights'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "def compute_bleu(model, inp_lines, out_lines, bpe_sep='@@ ', **flags):\n",
    "    \"\"\" Estimates corpora-level BLEU score of model's translations\n",
    "        given inp and reference out \"\"\"\n",
    "    translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "    # Note: if you experience out-of-memory error,\n",
    "    # split input lines into batches and translate separately\n",
    "    return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n",
    "\n",
    "def compute_bleu_large(model, inp_lines, out_lines):\n",
    "    batch_size = 256\n",
    "    result = 0.0\n",
    "    for i in range(0, inp_lines.shape[0], batch_size):\n",
    "        current_bleu = compute_bleu(model,\n",
    "                                    inp_lines[i:i+batch_size],\n",
    "                                    out_lines[i:i+batch_size])\n",
    "        current_bleu *= min(i + batch_size, inp_lines.shape[0]) - i\n",
    "        result += current_bleu\n",
    "    result /= inp_lines.shape[0]\n",
    "    return result\n",
    "def get_reversed(line):\n",
    "    return ''.join(reversed(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_config = AttentiveModel.Config(emb_size = 128,\n",
    "                                     hid_size = 256,\n",
    "                                     batch_size = 32,\n",
    "                                     ru_char_encoder_config = RuCharEncoder.deepspeare_en_config,\n",
    "                                     meter_config = MeterModel.deepspeare_config)\n",
    "model_name = 'translator_attn_reversed_amalgama_subtitles_with_pentameter_shakespeare_16_03_2019'\n",
    "\n",
    "if 'sess' in globals():\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = AttentiveModel(sess,\n",
    "                       filename = None,\n",
    "                       name = model_name,\n",
    "                       inp_voc = inp_voc,\n",
    "                       out_voc = out_voc,\n",
    "                       config = model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7feee7b41780>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator_inp = tf.placeholder('int32', [None, None])\n",
    "translator_out = tf.placeholder('int32', [None, None])\n",
    "translator_out_char = tf.placeholder('int32', [None, None, None])\n",
    "\n",
    "meter_inp = model.meter_model.get_input()\n",
    "meter_out = model.meter_model.get_output()\n",
    "\n",
    "translator_loss = model.compute_loss(translator_inp, translator_out, translator_out_char)\n",
    "translator_train_step = tf.train.AdamOptimizer().minimize(translator_loss)\n",
    "meter_loss = model.meter_model.pm_mean_cost\n",
    "meter_train_step = model.meter_model.pm_train_op\n",
    "K.get_session() # To not reset optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "metrics = {'train_loss': [], 'dev_bleu': [], 'meter_train_loss': []}\n",
    "sess.run(tf.global_variables_initializer())\n",
    "batch_size = model_config.batch_size\n",
    "dev_batch_size = 128\n",
    "\n",
    "def train_translator_and_pentameter(train_inp,\n",
    "                                    train_out,\n",
    "                                    dev_inp,\n",
    "                                    dev_out, iters):\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    #for _ in trange(iters):\n",
    "    for _ in range(iters):\n",
    "        step = len(metrics['train_loss']) + 1\n",
    "        \n",
    "        train_translator = True\n",
    "        train_meter = True\n",
    "        \n",
    "        if train_translator:\n",
    "            translator_batch_ix = np.random.choice(len(train_inp),\n",
    "                                                   size = batch_size,\n",
    "                                                   replace = False)\n",
    "\n",
    "            translator_out_tok_matrix = out_voc.to_matrix(train_out[translator_batch_ix])\n",
    "            translator_out_char_matrix = model.to_out_char_matrix(translator_out_tok_matrix)\n",
    "            translator_feed_dict = {\n",
    "                translator_inp: inp_voc.to_matrix(train_inp[translator_batch_ix]),\n",
    "                translator_out: translator_out_tok_matrix,\n",
    "                translator_out_char: translator_out_char_matrix,\n",
    "            }\n",
    "\n",
    "            translator_loss_t, _ = sess.run([translator_loss, translator_train_step],\n",
    "                                            translator_feed_dict)\n",
    "            metrics['train_loss'].append((step, translator_loss_t))\n",
    "        \n",
    "        if train_meter:\n",
    "            meter_batch_ix = set(list(np.random.choice(len(train_sonnet_lines_russian),\n",
    "                                                       size = batch_size,\n",
    "                                                       replace = False)))\n",
    "\n",
    "            meter_inp_lines = [x for i, x in enumerate(train_sonnet_lines_russian)\n",
    "                               if i in meter_batch_ix]\n",
    "            meter_out_stresses = [x for i, x in enumerate(train_sonnet_lines_russian_stresses)\n",
    "                                  if i in meter_batch_ix]\n",
    "            \n",
    "            assert len(meter_inp_lines) == len(meter_out_stresses) == batch_size\n",
    "\n",
    "            meter_feed_dict = {\n",
    "                meter_inp: model.to_meter_inp_char_matrix(meter_inp_lines),\n",
    "                meter_out: model.to_meter_out_stress_matrix(meter_out_stresses)\n",
    "            }\n",
    "\n",
    "            meter_loss_t, _ = sess.run([meter_loss, meter_train_step],\n",
    "                                       meter_feed_dict)\n",
    "            metrics['meter_train_loss'].append((step, meter_loss_t))\n",
    "        \n",
    "        \n",
    "\n",
    "        if step % 10 == 0:\n",
    "            batch_dev_ix = np.random.randint(len(dev_inp), size=dev_batch_size)\n",
    "            metrics['dev_bleu'].append((step, compute_bleu(model,\n",
    "                                                           dev_inp[batch_dev_ix],\n",
    "                                                           dev_out[batch_dev_ix])))\n",
    "\n",
    "            clear_output(True)\n",
    "            plt.figure(figsize=(12,10))\n",
    "            for i, (name, history) in enumerate(sorted(metrics.items())):\n",
    "                plt.subplot(2, 2, i + 1)\n",
    "                plt.title(name)\n",
    "                plt.plot(*zip(*history))\n",
    "                plt.grid()\n",
    "            plt.show()\n",
    "            print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0)[1],\n",
    "                  flush=True)\n",
    "        if step % 10000 == 0:\n",
    "            model.dump('{}.pkl'.format(model.name))\n",
    "    end = datetime.datetime.now()\n",
    "    print('Execution time: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss=4.151\n",
      "Execution time: 1:01:26.138286\n"
     ]
    }
   ],
   "source": [
    "train_translator_and_pentameter(\n",
    "    train_inp,\n",
    "    train_out,\n",
    "    dev_inp,\n",
    "    dev_out,\n",
    "    5001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
